{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ccspen21/greenland-fishery-nowcast-2025/blob/main/model_run_reports.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from IPython.display import display"
      ],
      "metadata": {
        "id": "O1qwmnPY5o-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Time Series of Fish Catch"
      ],
      "metadata": {
        "id": "7H42G2U7cPsE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A02AyJpqskn7"
      },
      "outputs": [],
      "source": [
        "# Time Series of Fish Catch\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "df_clean[\"Time\"] = df_clean[\"Year\"].astype(str) + \" \" + df_clean[\"Quarter\"]\n",
        "df_clean[\"Time_Index\"] = range(len(df_clean))\n",
        "\n",
        "# Plot the time series\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(df_clean[\"Time_Index\"], df_clean[\"Total_Catch\"], marker='o', linestyle='-')\n",
        "\n",
        "# Format x-axis: show only one label per year (use Q1 as the anchor)\n",
        "plt.xticks(\n",
        "    ticks=df_clean[df_clean[\"Quarter\"] == \"Q1\"][\"Time_Index\"],\n",
        "    labels=df_clean[df_clean[\"Quarter\"] == \"Q1\"][\"Year\"],\n",
        "    rotation=45\n",
        ")\n",
        "\n",
        "plt.xlabel(\"Year\")\n",
        "plt.ylabel(\"Total Catch (Tonnes)\")\n",
        "plt.title(\"Total Fish Catch Over Time\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.savefig('total_fish_catch_over_time.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Interaction Term"
      ],
      "metadata": {
        "id": "CtmAGUkMcgCb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create three-way interaction terms in each SST regional DataFrame\n",
        "df_sst_west_clean[\"Melt_SST_Interaction_West\"] = (\n",
        "    df_sst_west_clean[\"Melt_Active_West\"] *\n",
        "    df_sst_west_clean[\"Melt_Index_West\"] *\n",
        "    df_sst_west_clean[\"Sea_Surface_Temp_C_West\"]\n",
        ")\n",
        "\n",
        "df_sst_east_clean[\"Melt_SST_Interaction_East\"] = (\n",
        "    df_sst_east_clean[\"Melt_Active_East\"] *\n",
        "    df_sst_east_clean[\"Melt_Index_East\"] *\n",
        "    df_sst_east_clean[\"Sea_Surface_Temp_C_East\"]\n",
        ")\n",
        "\n",
        "df_sst_south_clean[\"Melt_SST_Interaction_South\"] = (\n",
        "    df_sst_south_clean[\"Melt_Active_South\"] *\n",
        "    df_sst_south_clean[\"Melt_Index_South\"] *\n",
        "    df_sst_south_clean[\"Sea_Surface_Temp_C_South\"]\n",
        ")"
      ],
      "metadata": {
        "id": "8thEvL9lWD0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Merged Dataset"
      ],
      "metadata": {
        "id": "euh2Hsjicr0k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGV5YQrx6c5o"
      },
      "outputs": [],
      "source": [
        "# Ensure all 'Year' and 'Quarter' columns are of consistent type across DataFrames\n",
        "def fix_keys(df):\n",
        "    df[\"Year\"] = df[\"Year\"].astype(int)\n",
        "    df[\"Quarter\"] = df[\"Quarter\"].astype(str).str.replace(\"quarter \", \"Q\").str.replace(\"Quarter \", \"Q\")\n",
        "    return df\n",
        "\n",
        "# Apply to all component DataFrames\n",
        "df_clean = fix_keys(df_clean)\n",
        "df_fish_clean = fix_keys(df_fish_clean)\n",
        "df_foreign_clean = fix_keys(df_foreign_clean)\n",
        "df_sst_west_clean = fix_keys(df_sst_west_clean)\n",
        "df_sst_east_clean = fix_keys(df_sst_east_clean)\n",
        "df_sst_south_clean = fix_keys(df_sst_south_clean)\n",
        "\n",
        "# Start fresh from df_clean\n",
        "df_merged_with_interactions = df_clean.copy()\n",
        "\n",
        "# Merge standard right-hand-side variables\n",
        "df_merged_with_interactions = df_merged_with_interactions.merge(df_fish_clean, on=[\"Year\", \"Quarter\"], how=\"inner\")\n",
        "\n",
        "# Merge SST interaction terms\n",
        "df_merged_with_interactions = df_merged_with_interactions.merge(\n",
        "    df_sst_west_clean[[\"Year\", \"Quarter\", \"Melt_SST_Interaction_West\"]],\n",
        "    on=[\"Year\", \"Quarter\"], how=\"inner\"\n",
        ").merge(\n",
        "    df_sst_east_clean[[\"Year\", \"Quarter\", \"Melt_SST_Interaction_East\"]],\n",
        "    on=[\"Year\", \"Quarter\"], how=\"inner\"\n",
        ").merge(\n",
        "    df_sst_south_clean[[\"Year\", \"Quarter\", \"Melt_SST_Interaction_South\"]],\n",
        "    on=[\"Year\", \"Quarter\"], how=\"inner\"\n",
        ")\n",
        "\n",
        "# Merge foreign catch\n",
        "df_merged_with_interactions = df_merged_with_interactions.merge(\n",
        "    df_foreign_clean.drop(columns=[\"Unit\"]),\n",
        "    on=[\"Year\", \"Quarter\"], how=\"left\"\n",
        ")\n",
        "\n",
        "# Drop unnecessary columns\n",
        "df_merged_with_interactions = df_merged_with_interactions.drop(\n",
        "    columns=[col for col in df_merged_with_interactions.columns if \"Unit\" in col], errors=\"ignore\"\n",
        ")\n",
        "df_merged_with_interactions = df_merged_with_interactions.drop(columns=[\"Time\", \"Time_Index\"], errors=\"ignore\")\n",
        "\n",
        "# Order\n",
        "df_merged_with_interactions[\"Quarter\"] = pd.Categorical(\n",
        "    df_merged_with_interactions[\"Quarter\"], categories=[\"Q1\", \"Q2\", \"Q3\", \"Q4\"], ordered=True\n",
        ")\n",
        "df_merged_with_interactions = df_merged_with_interactions.sort_values(by=[\"Year\", \"Quarter\"]).reset_index(drop=True)\n",
        "\n",
        "print(\"‚úÖ Final merged dataset shape:\", df_merged_with_interactions.shape)\n",
        "display(df_merged_with_interactions.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create df_model_with_interactions with Lagged Variables\n",
        "\n",
        "# Step 1: Identify predictors to lag (exclude Total_Catch and lagged versions)\n",
        "predictor_cols = [\n",
        "    col for col in df_merged_with_interactions.columns\n",
        "    if col not in [\"Year\", \"Quarter\", \"Total_Catch\"]\n",
        "    and not col.endswith(\"_lag1\")\n",
        "    and not col.endswith(\"_lag2\")\n",
        "    and not col.endswith(\"_lag3\")\n",
        "    and not col.endswith(\"_lag4\")\n",
        "]\n",
        "\n",
        "print(\"üîç Predictors to lag:\", predictor_cols)\n",
        "\n",
        "# Step 2: Add lags 1‚Äì4 for each selected predictor\n",
        "for col in predictor_cols:\n",
        "    for lag in [1, 2, 3, 4]:\n",
        "        df_merged_with_interactions[f\"{col}_lag{lag}\"] = df_merged_with_interactions[col].shift(lag)\n",
        "\n",
        "# Step 3: Add lags 1‚Äì4 for Total_Catch\n",
        "for lag in [1, 2, 3, 4]:\n",
        "    df_merged_with_interactions[f\"Total_Catch_lag{lag}\"] = df_merged_with_interactions[\"Total_Catch\"].shift(lag)\n",
        "\n",
        "# Step 4: Drop original (non-lagged) predictors\n",
        "df_model_with_interactions = df_merged_with_interactions.drop(columns=predictor_cols)\n",
        "\n",
        "# Step 5: Drop rows with NA from lagging\n",
        "df_model_with_interactions = df_model_with_interactions.dropna().reset_index(drop=True)\n",
        "\n",
        "# Step 6: Define modeling dataset\n",
        "y = df_model_with_interactions[\"Total_Catch\"]\n",
        "X = df_model_with_interactions.drop(columns=[\"Year\", \"Quarter\", \"Total_Catch\"])\n",
        "\n",
        "# ‚úÖ Final shape check\n",
        "print(\"‚úÖ Clean setup with lags 1‚Äì4 ‚Äî X shape:\", X.shape, \"y shape:\", y.shape)"
      ],
      "metadata": {
        "id": "JtXAmeFC5-Ur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary Statistics"
      ],
      "metadata": {
        "id": "6gM4yUEfc9Nr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Identify main (non-lagged) variables\n",
        "main_vars = [\n",
        "    col for col in df_merged_with_interactions.columns\n",
        "    if not col.endswith(\"_lag1\")\n",
        "    and not col.endswith(\"_lag2\")\n",
        "    and not col.endswith(\"_lag3\")\n",
        "    and not col.endswith(\"_lag4\")\n",
        "    and col not in [\"Year\", \"Quarter\"]\n",
        "]\n",
        "\n",
        "# Step 2: Subset numeric columns only (optional)\n",
        "main_df = df_merged_with_interactions[main_vars].select_dtypes(include=\"number\")\n",
        "\n",
        "# Step 3: Generate descriptive statistics\n",
        "summary_main = main_df.describe().T\n",
        "summary_main[\"missing\"] = main_df.isna().sum()\n",
        "summary_main[\"skew\"] = main_df.skew()\n",
        "summary_main[\"kurtosis\"] = main_df.kurt()\n",
        "\n",
        "# Round for cleaner presentation\n",
        "summary_main = summary_main.round(2)\n",
        "\n",
        "# Step 4: Display\n",
        "print(\"üìä Descriptive Statistics (Main Variables Only):\")\n",
        "display(summary_main)"
      ],
      "metadata": {
        "id": "5944unKlc8o-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Correlation Matrix"
      ],
      "metadata": {
        "id": "P6vZ5fB1dG1H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J08MzwD2LHib"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "main_vars = [\n",
        "    col for col in df_merged_with_interactions.columns\n",
        "    if not col.endswith(\"_lag1\") and not col.endswith(\"_lag2\")\n",
        "    and not col.endswith(\"_lag3\") and not col.endswith(\"_lag4\")\n",
        "    and col not in [\"Year\", \"Quarter\"]\n",
        "]\n",
        "\n",
        "main_corr = df_merged_with_interactions[main_vars].corr()\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(main_corr, cmap=\"coolwarm\", annot=True, fmt=\".2f\")\n",
        "plt.title(\"Correlation Matrix of Main (Non-Lagged) Variables\")\n",
        "plt.tight_layout()\n",
        "plt.savefig('correlation_matrix.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nowcasting Q1 2025"
      ],
      "metadata": {
        "id": "iSjkikGWblPg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "od2TJRdboIja"
      },
      "outputs": [],
      "source": [
        "# ‚úÖ Use all available data up to Q4 2024\n",
        "X_train_lasso_q1 = df_model_with_interactions[\n",
        "    (df_model_with_interactions[\"Year\"] < 2025)\n",
        "][[\n",
        "    \"Total_Catch_lag4\",\n",
        "    \"Melt_SST_Interaction_West_lag4\",\n",
        "    \"Foreign_Catch_lag4\",\n",
        "    \"Melt_SST_Interaction_East_lag1\",\n",
        "    \"Fish_Export_Value_Million_Kr_lag2\"\n",
        "]]\n",
        "\n",
        "y_train_lasso_q1 = df_model_with_interactions[\n",
        "    (df_model_with_interactions[\"Year\"] < 2025)\n",
        "][\"Total_Catch\"]\n",
        "\n",
        "# Step 2: Q1 2025 input for LASSO\n",
        "X_nowcast_lasso_q1 = pd.DataFrame([{\n",
        "    \"Total_Catch_lag4\": df_model_with_interactions.iloc[-4][\"Total_Catch_lag4\"],\n",
        "    \"Melt_SST_Interaction_West_lag4\": df_model_with_interactions.iloc[-4][\"Melt_SST_Interaction_West_lag4\"],\n",
        "    \"Foreign_Catch_lag4\": df_model_with_interactions.iloc[-4][\"Foreign_Catch_lag4\"],\n",
        "    \"Melt_SST_Interaction_East_lag1\": df_model_with_interactions.iloc[-1][\"Melt_SST_Interaction_East_lag1\"],\n",
        "    \"Fish_Export_Value_Million_Kr_lag2\": df_model_with_interactions.iloc[-4][\"Fish_Export_Value_Million_Kr_lag2\"]\n",
        "}])\n",
        "\n",
        "# Step 3: LASSO pipeline\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "lasso_pipeline_q1 = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    Lasso(alpha=1.0, max_iter=10000)\n",
        ")\n",
        "\n",
        "lasso_pipeline_q1.fit(X_train_lasso_q1, y_train_lasso_q1)\n",
        "\n",
        "# Step 4: Predict\n",
        "y_pred_lasso_q1 = lasso_pipeline_q1.predict(X_nowcast_lasso_q1)[0]\n",
        "print(f\"üìà LASSO Nowcast for Q1 2025: {round(y_pred_lasso_q1):,.0f} tons\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graph of Nowcast"
      ],
      "metadata": {
        "id": "OQy0L8MddqZ9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EgWKIHkIG8jP"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Rebuild time axis if needed\n",
        "df_clean[\"Time\"] = df_clean[\"Year\"].astype(str) + \" \" + df_clean[\"Quarter\"]\n",
        "df_clean[\"Time_Index\"] = range(len(df_clean))\n",
        "\n",
        "# Define the index and value for Q4 2024 (last actual) and Q1 2025 (nowcast)\n",
        "last_actual_index = df_clean[\"Time_Index\"].max()\n",
        "last_actual_value = df_clean[\"Total_Catch\"].iloc[-1]\n",
        "\n",
        "nowcast_index = last_actual_index + 1\n",
        "nowcast_value = y_pred_lasso_q1\n",
        "\n",
        "# Plot historical series\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(df_clean[\"Time_Index\"], df_clean[\"Total_Catch\"], marker='o', linestyle='-', label=\"Historical\")\n",
        "\n",
        "# Add red dot for nowcast\n",
        "plt.plot(nowcast_index, nowcast_value, 'ro', label=\"LASSO Nowcast (Q1 2025)\", markersize=8)\n",
        "\n",
        "# Add red connecting line from Q4 2024 to Q1 2025\n",
        "plt.plot([last_actual_index, nowcast_index], [last_actual_value, nowcast_value], color='red', linestyle='-', linewidth=2)\n",
        "\n",
        "# Update x-ticks to include 2025\n",
        "xticks = list(df_clean[df_clean[\"Quarter\"] == \"Q1\"][\"Time_Index\"])\n",
        "xticks_labels = list(df_clean[df_clean[\"Quarter\"] == \"Q1\"][\"Year\"].astype(str))\n",
        "xticks.append(nowcast_index)\n",
        "xticks_labels.append(\"2025\")\n",
        "\n",
        "plt.xticks(ticks=xticks, labels=xticks_labels, rotation=45)\n",
        "\n",
        "plt.text(\n",
        "    nowcast_index + 0.2,          # shift right\n",
        "    nowcast_value + 2000,         # shift upward\n",
        "    f\"{round(nowcast_value):,}\",\n",
        "    color=\"red\",\n",
        "    fontsize=9.5,\n",
        ")\n",
        "\n",
        "plt.axvspan(nowcast_index - 0.1, nowcast_index + 0.1, color='red', alpha=0.1)\n",
        "\n",
        "plt.axvline(nowcast_index, color='gray', linestyle='--', linewidth=1)\n",
        "\n",
        "# Labels and formatting\n",
        "plt.xlabel(\"Year\")\n",
        "plt.ylabel(\"Total Catch (Tonnes)\")\n",
        "plt.title(\"Total Fish Catch Over Time with LASSO Nowcast\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig('total_fish_catch_with_nowcast.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Capelin Dummy - Example of Policy Intervention"
      ],
      "metadata": {
        "id": "PpJm0uVwd-53"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note on Capelin Dummy\n",
        "The Capelin_Open dummy variable is introduced here to model the impact of policy interventions (e.g., fishery closures in 2019, 2020, 2024, and 2025). This variable is used specifically for nowcasting in this notebook and is not included in the LASSO model fitting performed in model_fitting_diagnostics.ipynb. This allows us to isolate the effect of policy shocks in our nowcast analysis.\n"
      ],
      "metadata": {
        "id": "677-Byes6ICz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWNVEKSNIFDn"
      },
      "outputs": [],
      "source": [
        "# Step 1: Start with a fresh copy\n",
        "df_with_capelin_dummy = df_model_with_interactions.copy()\n",
        "\n",
        "# Step 2: Add Capelin_Open dummy variable\n",
        "df_with_capelin_dummy[\"Capelin_Open\"] = df_with_capelin_dummy[\"Year\"].apply(\n",
        "    lambda x: 0 if x in [2019, 2020, 2024, 2025] else 1\n",
        ")\n",
        "\n",
        "# Step 3: Identify predictors to lag (excluding identifiers, Capelin_Open, and already-lagged variables)\n",
        "predictor_cols = [\n",
        "    col for col in df_with_capelin_dummy.columns\n",
        "    if col not in [\"Year\", \"Quarter\", \"Total_Catch\", \"Capelin_Open\"]\n",
        "    and not col.endswith(\"_lag1\")\n",
        "    and not col.endswith(\"_lag2\")\n",
        "    and not col.endswith(\"_lag3\")\n",
        "    and not col.endswith(\"_lag4\")\n",
        "]\n",
        "\n",
        "# Step 4: Add lags (1‚Äì4) for all predictors\n",
        "for col in predictor_cols:\n",
        "    for lag in [1, 2, 3, 4]:\n",
        "        df_with_capelin_dummy[f\"{col}_lag{lag}\"] = df_with_capelin_dummy[col].shift(lag)\n",
        "\n",
        "# Step 5: Add lags for Total Catch\n",
        "for lag in [1, 2, 3, 4]:\n",
        "    df_with_capelin_dummy[f\"Total_Catch_lag{lag}\"] = df_with_capelin_dummy[\"Total_Catch\"].shift(lag)\n",
        "\n",
        "# Step 6: Drop original non-lagged predictors (keep Capelin_Open)\n",
        "df_model_capelin = df_with_capelin_dummy.drop(columns=predictor_cols)\n",
        "\n",
        "# Step 7: Drop rows with NA caused by lagging\n",
        "df_model_capelin = df_model_capelin.dropna().reset_index(drop=True)\n",
        "\n",
        "# Step 8: Define target and features\n",
        "y_capelin = df_model_capelin[\"Total_Catch\"]\n",
        "X_capelin = df_model_capelin.drop(columns=[\"Year\", \"Quarter\", \"Total_Catch\"])\n",
        "\n",
        "# ‚úÖ Final check\n",
        "print(\"‚úÖ X_capelin shape:\", X_capelin.shape)\n",
        "print(\"‚úÖ y_capelin shape:\", y_capelin.shape)\n",
        "print(\"‚úÖ Final predictors:\", X_capelin.columns.tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nowcast with Capelin Dummy"
      ],
      "metadata": {
        "id": "f9p1NRDfeMqM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b48t71xQJrjh"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Step 1: Training data (up to Q4 2024)\n",
        "train_q1_2025_binary = df_model_capelin[\n",
        " \"Total_Catch_lag4\",\n",
        "    \"Foreign_Catch_lag4\",\n",
        "    \"Melt_SST_Interaction_West_lag4\",\n",
        "    \"Melt_SST_Interaction_East_lag1\",\n",
        "    \"Fish_Export_Value_Million_Kr_lag2\",\n",
        "    \"Capelin_Open\"\n",
        "]]\n",
        "y_train_q1_2025_binary = train_q1_2025_binary[\"Total_Catch\"]\n",
        "\n",
        "print(\"‚úÖ Training set size with Capelin dummy:\", X_train_q1_2025_binary.shape)\n",
        "\n",
        "# Step 2: Input row for Q1 2025\n",
        "latest_row_q4_binary = df_model_capelin[\n",
        "    (df_model_capelin[\"Year\"] == 2024) &\n",
        "    (df_model_capelin[\"Quarter\"] == \"Q4\")\n",
        "].iloc[0]\n",
        "\n",
        "X_nowcast_q1_2025_binary = pd.DataFrame([{\n",
        "    \"Total_Catch_lag4\": df_model_capelin.iloc[-4][\"Total_Catch_lag4\"],\n",
        "    \"Foreign_Catch_lag4\": df_model_capelin.iloc[-4][\"Foreign_Catch_lag4\"],\n",
        "    \"Melt_SST_Interaction_West_lag4\": df_model_capelin.iloc[-4][\"Melt_SST_Interaction_West_lag4\"],\n",
        "    \"Melt_SST_Interaction_East_lag1\": df_model_capelin.iloc[-1][\"Melt_SST_Interaction_East_lag1\"],\n",
        "    \"Fish_Export_Value_Million_Kr_lag2\": df_model_capelin.iloc[-4][\"Fish_Export_Value_Million_Kr_lag2\"],\n",
        "    \"Capelin_Open\": 0  # manually set to 0 because 2025 is closed\n",
        "}])\n",
        "\n",
        "print(\"‚úÖ Nowcast input for Q1 2025 with Capelin dummy:\")\n",
        "display(X_nowcast_q1_2025_binary)\n",
        "\n",
        "# Step 3: Lasso model pipeline\n",
        "lasso_pipeline_q1_binary = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    Lasso(alpha=1.0, max_iter=50000, random_state=42)  # You can tune alpha\n",
        ")\n",
        "\n",
        "# Step 4: Fit and predict\n",
        "lasso_pipeline_q1_binary.fit(X_train_q1_2025_binary, y_train_q1_2025_binary)\n",
        "y_pred_q1_2025_binary = lasso_pipeline_q1_binary.predict(X_nowcast_q1_2025_binary)[0]\n",
        "\n",
        "# Step 5: Output result\n",
        "print(f\"üìà üìä Lasso Nowcast for Q1 2025 (with Capelin dummy): {round(y_pred_q1_2025_binary):,.0f} tons\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Graph Comparison of Nowcasts"
      ],
      "metadata": {
        "id": "mqG16rGLeUHN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XrI2nK_nJr6d"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Rebuild time axis if needed\n",
        "df_clean[\"Time\"] = df_clean[\"Year\"].astype(str) + \" \" + df_clean[\"Quarter\"]\n",
        "df_clean[\"Time_Index\"] = range(len(df_clean))\n",
        "\n",
        "# Final observed point (Q4 2024)\n",
        "last_actual_index = df_clean[\"Time_Index\"].max()\n",
        "last_actual_value = df_clean[\"Total_Catch\"].iloc[-1]\n",
        "\n",
        "# Prediction point (Q1 2025)\n",
        "nowcast_index = last_actual_index + 1\n",
        "nowcast_std = y_pred_lasso_q1                 # Standard LASSO (no Capelin)\n",
        "nowcast_binary = y_pred_q1_2025_binary        # LASSO with Capelin dummy\n",
        "\n",
        "# Plot historical data\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(df_clean[\"Time_Index\"], df_clean[\"Total_Catch\"], marker='o', linestyle='-', label=\"Historical\")\n",
        "\n",
        "# Plot both nowcasts as dots\n",
        "plt.plot(nowcast_index, nowcast_std, 'ro', label=\"LASSO Nowcast (No Capelin)\", markersize=8)\n",
        "plt.plot(nowcast_index, nowcast_binary, 'go', label=\"LASSO Nowcast (With Capelin)\", markersize=8)\n",
        "\n",
        "# Connect last actual to each forecast\n",
        "plt.plot([last_actual_index, nowcast_index], [last_actual_value, nowcast_std],\n",
        "         color='red', linestyle='-', linewidth=2)\n",
        "plt.plot([last_actual_index, nowcast_index], [last_actual_value, nowcast_binary],\n",
        "         color='green', linestyle='-', linewidth=2)\n",
        "\n",
        "# Annotate both nowcast values\n",
        "plt.text(nowcast_index + 0.2, nowcast_std + 2000,\n",
        "         f\"{round(nowcast_std):,}\", color=\"red\", fontsize=9.5)\n",
        "\n",
        "plt.text(nowcast_index + 0.2, nowcast_binary + 2000,\n",
        "         f\"{round(nowcast_binary):,}\", color=\"green\", fontsize=9.5)\n",
        "\n",
        "# Forecast area shading and vertical marker\n",
        "plt.axvspan(nowcast_index - 0.1, nowcast_index + 0.1, color='gray', alpha=0.1)\n",
        "plt.axvline(nowcast_index, color='gray', linestyle='--', linewidth=1)\n",
        "\n",
        "# X-axis setup\n",
        "xticks = list(df_clean[df_clean[\"Quarter\"] == \"Q1\"][\"Time_Index\"])\n",
        "xticks_labels = list(df_clean[df_clean[\"Quarter\"] == \"Q1\"][\"Year\"].astype(str))\n",
        "xticks.append(nowcast_index)\n",
        "xticks_labels.append(\"2025\")\n",
        "plt.xticks(ticks=xticks, labels=xticks_labels, rotation=45)\n",
        "\n",
        "# Labels and formatting\n",
        "plt.xlabel(\"Year\")\n",
        "plt.ylabel(\"Total Catch (Tonnes)\")\n",
        "plt.title(\"Total Fish Catch Over Time: LASSO Nowcast With and Without Capelin Dummy\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig('nowcast_comparison.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Actual vs. Predicted Plot for Backtests"
      ],
      "metadata": {
        "id": "DNerKdzLdebk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0FBO0cuElWz"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the quarters and values\n",
        "quarters = [\"Q1 2024\", \"Q2 2024\", \"Q3 2024\", \"Q4 2024\"]\n",
        "actual_values = [actual_q1, actual_q2, actual_q3, actual_q4]\n",
        "predicted_values = [\n",
        "    y_pred_q1_2024_lasso,\n",
        "    y_pred_q2_2024_lasso,\n",
        "    y_pred_q3_2024_lasso,\n",
        "    y_pred_q4_2024_lasso\n",
        "]\n",
        "\n",
        "# Calculate y-axis padding\n",
        "all_values = actual_values + predicted_values\n",
        "y_min = min(all_values) * 0.9  # 10% below\n",
        "y_max = max(all_values) * 1.1  # 10% above\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(quarters, actual_values, label=\"Actual\", marker='o', linewidth=2)\n",
        "plt.plot(quarters, predicted_values, label=\"LASSO Prediction\", marker='o', linewidth=2)\n",
        "plt.ylim(y_min, y_max)\n",
        "plt.title(\"üìä Actual vs. Predicted Fish Catch (LASSO, Q1‚ÄìQ4 2024)\")\n",
        "plt.xlabel(\"Quarter\")\n",
        "plt.ylabel(\"Total_Catch (tons)\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig('actual_vs_predicted.png')"
      ]
    }
  ]
}