{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP4WlH1eVdiwLPvJ+2q1J3d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ccspen21/greenland-fishery-nowcast-2025/blob/main/periodic_update.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kg2LslY3Up8a"
      },
      "outputs": [],
      "source": [
        "!pip install requests xarray pandas pyjstat datetime pydap netCDF4\n",
        "import os\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "import requests\n",
        "from pyjstat import pyjstat\n",
        "from urllib.parse import quote\n",
        "from io import StringIO\n",
        "from IPython.display import display\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "# Ensure compatibility with Colab and GitHub\n",
        "!apt-get update && apt-get install -y iputils-ping\n",
        "\n",
        "# Define a configurable database path\n",
        "DB_PATH = os.getenv(\"DB_PATH\", \"greenland_fishery.db\")  # Use environment variable or default to local file"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to the SQLite database\n",
        "conn = sqlite3.connect(DB_PATH)\n",
        "cursor = conn.cursor()\n",
        "print(f\"Connected to SQLite database at {DB_PATH}\")\n",
        "\n",
        "# Function to execute SQL scripts (for DML updates)\n",
        "def execute_sql_script(file_path):\n",
        "    try:\n",
        "        with open(file_path, 'r') as file:\n",
        "            sql_script = file.read()\n",
        "        cursor.executescript(sql_script)\n",
        "        conn.commit()\n",
        "        print(f\"Successfully executed SQL script: {file_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error executing SQL script {file_path}: {e}\")\n",
        "        raise"
      ],
      "metadata": {
        "id": "XsZIYHGVVYxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function to validate DataFrame against schema\n",
        "def validate_dataframe(df, expected_columns, dtypes):\n",
        "    if not all(col in df.columns for col in expected_columns):\n",
        "        raise ValueError(f\"DataFrame missing expected columns: {expected_columns}\")\n",
        "    for col, dtype in dtypes.items():\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col].astype(dtype)\n",
        "    if df.isnull().any().any():\n",
        "        raise ValueError(f\"DataFrame contains NaN values: {df.head()}\")"
      ],
      "metadata": {
        "id": "u7xATA1NVh-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UPDATE TOTAL CATCH\n",
        "\n",
        "# Define quarter to months mapping for SST updates\n",
        "quarter_to_months = {\n",
        "    \"Q1\": (\"01-01\", \"03-31\"),\n",
        "    \"Q2\": (\"04-01\", \"06-30\"),\n",
        "    \"Q3\": (\"07-01\", \"09-30\"),\n",
        "    \"Q4\": (\"10-01\", \"12-31\")\n",
        "}\n",
        "\n",
        "# Determine the most recent data point in the total_catch table\n",
        "cursor.execute(\"SELECT MAX(Year), Quarter FROM total_catch WHERE Year = (SELECT MAX(Year) FROM total_catch)\")\n",
        "result = cursor.fetchone()\n",
        "if result and result[0] is not None:\n",
        "    latest_year, latest_quarter = result\n",
        "    print(f\"Latest data point: {latest_year} {latest_quarter}\")\n",
        "else:\n",
        "    latest_year, latest_quarter = 2010, \"Q4\"  # Fallback to start of range\n",
        "    print(\"No data found in total_catch, starting from 2010 Q4\")\n",
        "\n",
        "# Determine the next quarter to fetch\n",
        "quarter_order = [\"Q1\", \"Q2\", \"Q3\", \"Q4\"]\n",
        "next_quarter_idx = (quarter_order.index(latest_quarter) + 1) % 4\n",
        "next_year = latest_year if next_quarter_idx != 0 else latest_year + 1\n",
        "next_quarter = quarter_order[next_quarter_idx]\n",
        "print(f\"Fetching data for: {next_year} {next_quarter}\")\n",
        "\n",
        "# Fetch new data from the API\n",
        "url = \"https://bank.stat.gl:443/api/v1/en/Greenland/FI/FI10/FIX008.px\"\n",
        "query = {\n",
        "    \"query\": [\n",
        "        {\"code\": \"nation\", \"selection\": {\"filter\": \"item\", \"values\": [\"GRL\"]}},\n",
        "        {\"code\": \"unit\", \"selection\": {\"filter\": \"item\", \"values\": [\"Ton\"]}},\n",
        "        {\"code\": \"time\", \"selection\": {\"filter\": \"item\", \"values\": [str(next_year)]}},\n",
        "        {\"code\": \"quarter\", \"selection\": {\"filter\": \"item\", \"values\": [str(next_quarter_idx + 1)]}}\n",
        "    ],\n",
        "    \"response\": {\"format\": \"json-stat2\"}\n",
        "}\n",
        "try:\n",
        "    response = requests.post(url, json=query, timeout=30)\n",
        "    response.raise_for_status()\n",
        "    dataset = pyjstat.Dataset.read(response.text)\n",
        "    df = dataset.write('dataframe')\n",
        "    print(\"Data successfully retrieved and converted to DataFrame!\")\n",
        "\n",
        "    # Clean DataFrame\n",
        "    df_new = df.copy()\n",
        "    df_new.drop(columns=['nation'], inplace=True)\n",
        "    df_new.rename(columns={\n",
        "        \"time\": \"Year\",\n",
        "        \"quarter\": \"Quarter\",\n",
        "        \"unit\": \"Unit\",\n",
        "        \"value\": \"Total_Catch\"\n",
        "    }, inplace=True)\n",
        "    df_new[\"Quarter\"] = df_new[\"Quarter\"].str.replace(\"Quarter \", \"Q\")\n",
        "    df_new[\"Quarter\"] = pd.Categorical(df_new[\"Quarter\"], categories=quarter_order, ordered=True)\n",
        "    df_new = df_new[[\"Year\", \"Quarter\", \"Unit\", \"Total_Catch\"]]\n",
        "    df_new[\"Year\"] = df_new[\"Year\"].astype(int)\n",
        "\n",
        "    # Validate before updating SQLite\n",
        "    expected_columns = [\"Year\", \"Quarter\", \"Unit\", \"Total_Catch\"]\n",
        "    dtypes = {\"Year\": int, \"Quarter\": str, \"Unit\": str, \"Total_Catch\": int}\n",
        "    validate_dataframe(df_new, expected_columns, dtypes)\n",
        "\n",
        "    # Generate DML statements for insertion\n",
        "    dml_statements = []\n",
        "    for _, row in df_new.iterrows():\n",
        "        dml_statements.append(\n",
        "            f\"INSERT INTO total_catch (Year, Quarter, Unit, Total_Catch) VALUES \"\n",
        "            f\"({row['Year']}, '{row['Quarter']}', '{row['Unit']}', {row['Total_Catch']})\"\n",
        "        )\n",
        "\n",
        "    # Append DML statements to dml_populate.sql\n",
        "    with open('dml_populate.sql', 'a') as f:\n",
        "        f.write(\"\\n-- Update for total_catch\\n\")\n",
        "        f.write(\"\\n\".join(dml_statements) + \";\\n\")\n",
        "\n",
        "    # Execute the DML script\n",
        "    execute_sql_script('dml_populate.sql')\n",
        "    print(\"Updated total_catch table with new data\")\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error fetching new Total Catch data: {e}\")\n",
        "\n",
        "# Final display\n",
        "print(\"Updated Total Catch DataFrame:\")\n",
        "df_updated = pd.read_sql_query(\"SELECT * FROM total_catch WHERE Year = ? AND Quarter = ?\", conn, params=(next_year, next_quarter))\n",
        "display(df_updated)"
      ],
      "metadata": {
        "id": "wbDAgN3LVift"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UPDATE FISH EXPORTS\n",
        "\n",
        "# Determine the most recent data point in the fish_exports table\n",
        "cursor.execute(\"SELECT MAX(Year), Quarter FROM fish_exports WHERE Year = (SELECT MAX(Year) FROM fish_exports)\")\n",
        "result = cursor.fetchone()\n",
        "if result and result[0] is not None:\n",
        "    latest_year, latest_quarter = result\n",
        "    print(f\"Latest data point: {latest_year} {latest_quarter}\")\n",
        "else:\n",
        "    latest_year, latest_quarter = 2010, \"Q4\"  # Fallback to start of range\n",
        "    print(\"No data found in fish_exports, starting from 2010 Q4\")\n",
        "\n",
        "# Determine the next quarter to fetch\n",
        "quarter_order = [\"Q1\", \"Q2\", \"Q3\", \"Q4\"]\n",
        "next_quarter_idx = (quarter_order.index(latest_quarter) + 1) % 4\n",
        "next_year = latest_year if next_quarter_idx != 0 else latest_year + 1\n",
        "next_quarter = quarter_order[next_quarter_idx]\n",
        "print(f\"Fetching data for: {next_year} {next_quarter}\")\n",
        "\n",
        "# Fetch new data from the API\n",
        "url = \"https://bank.stat.gl:443/api/v1/en/Greenland/BE/BE80/BEXSTA22.px\"\n",
        "query = {\n",
        "    \"query\": [\n",
        "        {\"code\": \"unit\", \"selection\": {\"filter\": \"item\", \"values\": [\"Mill. kr.\"]}},\n",
        "        {\"code\": \"time\", \"selection\": {\"filter\": \"item\", \"values\": [str(next_year)]}},\n",
        "        {\"code\": \"quarter\", \"selection\": {\"filter\": \"item\", \"values\": [str(next_quarter_idx + 1)]}}\n",
        "    ],\n",
        "    \"response\": {\"format\": \"json-stat2\"}\n",
        "}\n",
        "try:\n",
        "    response = requests.post(url, json=query, timeout=30)\n",
        "    response.raise_for_status()\n",
        "    dataset = pyjstat.Dataset.read(response.text)\n",
        "    df = dataset.write('dataframe')\n",
        "    print(\"Data successfully retrieved and converted to DataFrame!\")\n",
        "\n",
        "    # Clean DataFrame\n",
        "    df_new = df.copy()\n",
        "    df_new.rename(columns={\n",
        "        \"time\": \"Year\",\n",
        "        \"quarter\": \"Quarter\",\n",
        "        \"value\": \"Fish_Export_Value_Million_Kr\"\n",
        "    }, inplace=True)\n",
        "    df_new[\"Quarter\"] = df_new[\"Quarter\"].str.replace(\"Quarter \", \"Q\")\n",
        "    df_new[\"Quarter\"] = pd.Categorical(df_new[\"Quarter\"], categories=quarter_order, ordered=True)\n",
        "    df_new = df_new[[\"Year\", \"Quarter\", \"Fish_Export_Value_Million_Kr\"]]\n",
        "    df_new[\"Year\"] = df_new[\"Year\"].astype(int)\n",
        "\n",
        "    # Validate before updating SQLite\n",
        "    expected_columns = [\"Year\", \"Quarter\", \"Fish_Export_Value_Million_Kr\"]\n",
        "    dtypes = {\"Year\": int, \"Quarter\": str, \"Fish_Export_Value_Million_Kr\": int}\n",
        "    validate_dataframe(df_new, expected_columns, dtypes)\n",
        "\n",
        "    # Generate DML statements for insertion\n",
        "    dml_statements = []\n",
        "    for _, row in df_new.iterrows():\n",
        "        dml_statements.append(\n",
        "            f\"INSERT INTO fish_exports (Year, Quarter, Fish_Export_Value_Million_Kr) VALUES \"\n",
        "            f\"({row['Year']}, '{row['Quarter']}', {row['Fish_Export_Value_Million_Kr']})\"\n",
        "        )\n",
        "\n",
        "    # Append DML statements to dml_populate.sql\n",
        "    with open('dml_populate.sql', 'a') as f:\n",
        "        f.write(\"\\n-- Update for fish_exports\\n\")\n",
        "        f.write(\"\\n\".join(dml_statements) + \";\\n\")\n",
        "\n",
        "    # Execute the DML script\n",
        "    execute_sql_script('dml_populate.sql')\n",
        "    print(\"Updated fish_exports table with new data\")\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error fetching new Fish Exports data: {e}\")\n",
        "\n",
        "# Final display\n",
        "print(\"Updated Fish Exports DataFrame:\")\n",
        "df_updated = pd.read_sql_query(\"SELECT * FROM fish_exports WHERE Year = ? AND Quarter = ?\", conn, params=(next_year, next_quarter))\n",
        "display(df_updated)"
      ],
      "metadata": {
        "id": "Gxopz6AnVoaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UPDATE WEST GREENLAND SST\n",
        "\n",
        "# Degree to ERDDAP grid index conversion\n",
        "def deg_to_index_lat(lat): return int(round((lat + 90) / 0.25))\n",
        "def deg_to_index_lon(lon): return int(round((lon + 180) / 0.25))\n",
        "\n",
        "# Define bounding box in degrees for West Greenland\n",
        "bbox_deg_west = {\n",
        "    'lat_min': 65.0,\n",
        "    'lat_max': 70.0,\n",
        "    'lon_min': -55.0,\n",
        "    'lon_max': -50.0\n",
        "}\n",
        "\n",
        "# Convert to grid indices\n",
        "bbox_idx_west = {\n",
        "    'lat_min': deg_to_index_lat(bbox_deg_west['lat_min']),\n",
        "    'lat_max': deg_to_index_lat(bbox_deg_west['lat_max']),\n",
        "    'lon_min': deg_to_index_lon(bbox_deg_west['lon_min']),\n",
        "    'lon_max': deg_to_index_lon(bbox_deg_west['lon_max'])\n",
        "}\n",
        "\n",
        "# Determine the most recent data point in the sst_west table\n",
        "cursor.execute(\"SELECT MAX(Year), Quarter FROM sst_west WHERE Year = (SELECT MAX(Year) FROM sst_west)\")\n",
        "result = cursor.fetchone()\n",
        "if result and result[0] is not None:\n",
        "    latest_year, latest_quarter = result\n",
        "    print(f\"Latest data point: {latest_year} {latest_quarter}\")\n",
        "else:\n",
        "    latest_year, latest_quarter = 2010, \"Q4\"  # Fallback to start of range\n",
        "    print(\"No data found in sst_west, starting from 2010 Q4\")\n",
        "\n",
        "# Determine the next quarter to fetch\n",
        "quarter_order = [\"Q1\", \"Q2\", \"Q3\", \"Q4\"]\n",
        "next_quarter_idx = (quarter_order.index(latest_quarter) + 1) % 4\n",
        "next_year = latest_year if next_quarter_idx != 0 else latest_year + 1\n",
        "next_quarter = quarter_order[next_quarter_idx]\n",
        "print(f\"Fetching data for: {next_year} {next_quarter}\")\n",
        "\n",
        "# Map quarter to months\n",
        "quarter_to_months = {\n",
        "    \"Q1\": (\"01-01\", \"03-31\"),\n",
        "    \"Q2\": (\"04-01\", \"06-30\"),\n",
        "    \"Q3\": (\"07-01\", \"09-30\"),\n",
        "    \"Q4\": (\"10-01\", \"12-31\")\n",
        "}\n",
        "start_month, end_month = quarter_to_months[next_quarter]\n",
        "\n",
        "# Fetch new data from the API\n",
        "try:\n",
        "    base = \"https://coastwatch.pfeg.noaa.gov/erddap/griddap/ncdcOisst21Agg_LonPM180.csv?\"\n",
        "    var = \"sst\"\n",
        "    time = f\"[({next_year}-{start_month}T00:00:00Z):1:({next_year}-{end_month}T00:00:00Z)]\".replace(\" \", \"\")\n",
        "    zlev = \"[0:1:0]\"\n",
        "    lat = f\"[({bbox_idx_west['lat_min']}):1:({bbox_idx_west['lat_max']})]\"\n",
        "    lon = f\"[({bbox_idx_west['lon_min']}):1:({bbox_idx_west['lon_max']})]\"\n",
        "    query = f\"{var}{time}{zlev}{lat}{lon}\"\n",
        "    full_url = base + quote(query, safe=\":/[](),-T\")\n",
        "    print(\"Constructed URL:\", full_url)\n",
        "\n",
        "    response = requests.get(full_url, timeout=30)\n",
        "    response.raise_for_status()\n",
        "\n",
        "    df = pd.read_csv(StringIO(response.text), skiprows=[1])\n",
        "    df = df.rename(columns={col: col.strip() for col in df.columns})\n",
        "    df = df.dropna(subset=[\"sst\"])\n",
        "\n",
        "    df[\"time\"] = pd.to_datetime(df[\"time\"])\n",
        "    df[\"Year\"] = df[\"time\"].dt.year.astype(int)\n",
        "    df[\"Quarter\"] = \"Q\" + df[\"time\"].dt.quarter.astype(str)\n",
        "\n",
        "    df_new = df.groupby(['Year', 'Quarter'])[\"sst\"].mean().reset_index()\n",
        "    df_new = df_new.rename(columns={\"sst\": \"Sea_Surface_Temp_C_West\"})\n",
        "\n",
        "    df_new[\"Melt_Active_West\"] = (df_new[\"Sea_Surface_Temp_C_West\"] > 0.5).astype(int)\n",
        "    df_new[\"Melt_Index_West\"] = df_new[\"Sea_Surface_Temp_C_West\"].clip(lower=0, upper=4) / 4\n",
        "\n",
        "    # Validate before updating SQLite\n",
        "    expected_columns = [\"Year\", \"Quarter\", \"Sea_Surface_Temp_C_West\", \"Melt_Active_West\", \"Melt_Index_West\"]\n",
        "    dtypes = {\"Year\": int, \"Quarter\": str, \"Sea_Surface_Temp_C_West\": float, \"Melt_Active_West\": int, \"Melt_Index_West\": float}\n",
        "    validate_dataframe(df_new, expected_columns, dtypes)\n",
        "\n",
        "    # Generate DML statements for insertion\n",
        "    dml_statements = []\n",
        "    for _, row in df_new.iterrows():\n",
        "        dml_statements.append(\n",
        "            f\"INSERT INTO sst_west (Year, Quarter, Sea_Surface_Temp_C_West, Melt_Active_West, Melt_Index_West) VALUES \"\n",
        "            f\"({row['Year']}, '{row['Quarter']}', {row['Sea_Surface_Temp_C_West']}, {row['Melt_Active_West']}, {row['Melt_Index_West']})\"\n",
        "        )\n",
        "\n",
        "    # Append DML statements to dml_populate.sql\n",
        "    with open('dml_populate.sql', 'a') as f:\n",
        "        f.write(\"\\n-- Update for sst_west\\n\")\n",
        "        f.write(\"\\n\".join(dml_statements) + \";\\n\")\n",
        "\n",
        "    # Execute the DML script\n",
        "    execute_sql_script('dml_populate.sql')\n",
        "    print(\"Updated sst_west table with new data\")\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error fetching new SST West data: {e}\")\n",
        "\n",
        "# Final display\n",
        "print(\"Updated SST West DataFrame:\")\n",
        "df_updated = pd.read_sql_query(\"SELECT * FROM sst_west WHERE Year = ? AND Quarter = ?\", conn, params=(next_year, next_quarter))\n",
        "display(df_updated)"
      ],
      "metadata": {
        "id": "bp6KAn4AVq0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UPDATE EAST GREENLAND SST\n",
        "\n",
        "# Define bounding box in degrees for East Greenland\n",
        "bbox_deg_east = {\n",
        "    'lat_min': 65.0,\n",
        "    'lat_max': 70.0,\n",
        "    'lon_min': -40.0,\n",
        "    'lon_max': -35.0\n",
        "}\n",
        "\n",
        "# Convert to grid indices\n",
        "bbox_idx_east = {\n",
        "    'lat_min': deg_to_index_lat(bbox_deg_east['lat_min']),\n",
        "    'lat_max': deg_to_index_lat(bbox_deg_east['lat_max']),\n",
        "    'lon_min': deg_to_index_lon(bbox_deg_east['lon_min']),\n",
        "    'lon_max': deg_to_index_lon(bbox_deg_east['lon_max'])\n",
        "}\n",
        "\n",
        "# Determine the most recent data point in the sst_east table\n",
        "cursor.execute(\"SELECT MAX(Year), Quarter FROM sst_east WHERE Year = (SELECT MAX(Year) FROM sst_east)\")\n",
        "result = cursor.fetchone()\n",
        "if result and result[0] is not None:\n",
        "    latest_year, latest_quarter = result\n",
        "    print(f\"Latest data point: {latest_year} {latest_quarter}\")\n",
        "else:\n",
        "    latest_year, latest_quarter = 2010, \"Q4\"  # Fallback to start of range\n",
        "    print(\"No data found in sst_east, starting from 2010 Q4\")\n",
        "\n",
        "# Determine the next quarter to fetch\n",
        "quarter_order = [\"Q1\", \"Q2\", \"Q3\", \"Q4\"]\n",
        "next_quarter_idx = (quarter_order.index(latest_quarter) + 1) % 4\n",
        "next_year = latest_year if next_quarter_idx != 0 else latest_year + 1\n",
        "next_quarter = quarter_order[next_quarter_idx]\n",
        "print(f\"Fetching data for: {next_year} {next_quarter}\")\n",
        "\n",
        "# Map quarter to months\n",
        "start_month, end_month = quarter_to_months[next_quarter]\n",
        "\n",
        "# Fetch new data from the API\n",
        "try:\n",
        "    base = \"https://coastwatch.pfeg.noaa.gov/erddap/griddap/ncdcOisst21Agg_LonPM180.csv?\"\n",
        "    var = \"sst\"\n",
        "    time = f\"[({next_year}-{start_month}T00:00:00Z):1:({next_year}-{end_month}T00:00:00Z)]\".replace(\" \", \"\")\n",
        "    zlev = \"[0:1:0]\"\n",
        "    lat = f\"[({bbox_idx_east['lat_min']}):1:({bbox_idx_east['lat_max']})]\"\n",
        "    lon = f\"[({bbox_idx_east['lon_min']}):1:({bbox_idx_east['lon_max']})]\"\n",
        "    query = f\"{var}{time}{zlev}{lat}{lon}\"\n",
        "    full_url = base + quote(query, safe=\":/[](),-T\")\n",
        "    print(\"Constructed URL:\", full_url)\n",
        "\n",
        "    response = requests.get(full_url, timeout=30)\n",
        "    response.raise_for_status()\n",
        "\n",
        "    df = pd.read_csv(StringIO(response.text), skiprows=[1])\n",
        "    df = df.rename(columns={col: col.strip() for col in df.columns})\n",
        "    df = df.dropna(subset=[\"sst\"])\n",
        "\n",
        "    df[\"time\"] = pd.to_datetime(df[\"time\"])\n",
        "    df[\"Year\"] = df[\"time\"].dt.year.astype(int)\n",
        "    df[\"Quarter\"] = \"Q\" + df[\"time\"].dt.quarter.astype(str)\n",
        "\n",
        "    df_new = df.groupby(['Year', 'Quarter'])[\"sst\"].mean().reset_index()\n",
        "    df_new = df_new.rename(columns={\"sst\": \"Sea_Surface_Temp_C_East\"})\n",
        "\n",
        "    df_new[\"Melt_Active_East\"] = (df_new[\"Sea_Surface_Temp_C_East\"] > 0.5).astype(int)\n",
        "    df_new[\"Melt_Index_East\"] = df_new[\"Sea_Surface_Temp_C_East\"].clip(lower=0, upper=4) / 4\n",
        "\n",
        "    # Validate before updating SQLite\n",
        "    expected_columns = [\"Year\", \"Quarter\", \"Sea_Surface_Temp_C_East\", \"Melt_Active_East\", \"Melt_Index_East\"]\n",
        "    dtypes = {\"Year\": int, \"Quarter\": str, \"Sea_Surface_Temp_C_East\": float, \"Melt_Active_East\": int, \"Melt_Index_East\": float}\n",
        "    validate_dataframe(df_new, expected_columns, dtypes)\n",
        "\n",
        "    # Generate DML statements for insertion\n",
        "    dml_statements = []\n",
        "    for _, row in df_new.iterrows():\n",
        "        dml_statements.append(\n",
        "            f\"INSERT INTO sst_east (Year, Quarter, Sea_Surface_Temp_C_East, Melt_Active_East, Melt_Index_East) VALUES \"\n",
        "            f\"({row['Year']}, '{row['Quarter']}', {row['Sea_Surface_Temp_C_East']}, {row['Melt_Active_East']}, {row['Melt_Index_East']})\"\n",
        "        )\n",
        "\n",
        "    # Append DML statements to dml_populate.sql\n",
        "    with open('dml_populate.sql', 'a') as f:\n",
        "        f.write(\"\\n-- Update for sst_east\\n\")\n",
        "        f.write(\"\\n\".join(dml_statements) + \";\\n\")\n",
        "\n",
        "    # Execute the DML script\n",
        "    execute_sql_script('dml_populate.sql')\n",
        "    print(\"Updated sst_east table with new data\")\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error fetching new SST East data: {e}\")\n",
        "\n",
        "# Final display\n",
        "print(\"Updated SST East DataFrame:\")\n",
        "df_updated = pd.read_sql_query(\"SELECT * FROM sst_east WHERE Year = ? AND Quarter = ?\", conn, params=(next_year, next_quarter))\n",
        "display(df_updated)"
      ],
      "metadata": {
        "id": "Y90B8JbvxBPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UPDATE SOUTH GREENLAND SST\n",
        "\n",
        "# Define bounding box in degrees for South Greenland\n",
        "bbox_deg_south = {\n",
        "    'lat_min': 60.0,\n",
        "    'lat_max': 65.0,\n",
        "    'lon_min': -45.0,\n",
        "    'lon_max': -40.0\n",
        "}\n",
        "\n",
        "# Convert to grid indices\n",
        "bbox_idx_south = {\n",
        "    'lat_min': deg_to_index_lat(bbox_deg_south['lat_min']),\n",
        "    'lat_max': deg_to_index_lat(bbox_deg_south['lat_max']),\n",
        "    'lon_min': deg_to_index_lon(bbox_deg_south['lon_min']),\n",
        "    'lon_max': deg_to_index_lon(bbox_deg_south['lon_max'])\n",
        "}\n",
        "\n",
        "# Determine the most recent data point in the sst_south table\n",
        "cursor.execute(\"SELECT MAX(Year), Quarter FROM sst_south WHERE Year = (SELECT MAX(Year) FROM sst_south)\")\n",
        "result = cursor.fetchone()\n",
        "if result and result[0] is not None:\n",
        "    latest_year, latest_quarter = result\n",
        "    print(f\"Latest data point: {latest_year} {latest_quarter}\")\n",
        "else:\n",
        "    latest_year, latest_quarter = 2010, \"Q4\"  # Fallback to start of range\n",
        "    print(\"No data found in sst_south, starting from 2010 Q4\")\n",
        "\n",
        "# Determine the next quarter to fetch\n",
        "quarter_order = [\"Q1\", \"Q2\", \"Q3\", \"Q4\"]\n",
        "next_quarter_idx = (quarter_order.index(latest_quarter) + 1) % 4\n",
        "next_year = latest_year if next_quarter_idx != 0 else latest_year + 1\n",
        "next_quarter = quarter_order[next_quarter_idx]\n",
        "print(f\"Fetching data for: {next_year} {next_quarter}\")\n",
        "\n",
        "# Map quarter to months\n",
        "start_month, end_month = quarter_to_months[next_quarter]\n",
        "\n",
        "# Fetch new data from the API\n",
        "try:\n",
        "    base = \"https://coastwatch.pfeg.noaa.gov/erddap/griddap/ncdcOisst21Agg_LonPM180.csv?\"\n",
        "    var = \"sst\"\n",
        "    time = f\"[({next_year}-{start_month}T00:00:00Z):1:({next_year}-{end_month}T00:00:00Z)]\".replace(\" \", \"\")\n",
        "    zlev = \"[0:1:0]\"\n",
        "    lat = f\"[({bbox_idx_south['lat_min']}):1:({bbox_idx_south['lat_max']})]\"\n",
        "    lon = f\"[({bbox_idx_south['lon_min']}):1:({bbox_idx_south['lon_max']})]\"\n",
        "    query = f\"{var}{time}{zlev}{lat}{lon}\"\n",
        "    full_url = base + quote(query, safe=\":/[](),-T\")\n",
        "    print(\"Constructed URL:\", full_url)\n",
        "\n",
        "    response = requests.get(full_url, timeout=30)\n",
        "    response.raise_for_status()\n",
        "\n",
        "    df = pd.read_csv(StringIO(response.text), skiprows=[1])\n",
        "    df = df.rename(columns={col: col.strip() for col in df.columns})\n",
        "    df = df.dropna(subset=[\"sst\"])\n",
        "\n",
        "    df[\"time\"] = pd.to_datetime(df[\"time\"])\n",
        "    df[\"Year\"] = df[\"time\"].dt.year.astype(int)\n",
        "    df[\"Quarter\"] = \"Q\" + df[\"time\"].dt.quarter.astype(str)\n",
        "\n",
        "    df_new = df.groupby(['Year', 'Quarter'])[\"sst\"].mean().reset_index()\n",
        "    df_new = df_new.rename(columns={\"sst\": \"Sea_Surface_Temp_C_South\"})\n",
        "\n",
        "    df_new[\"Melt_Active_South\"] = (df_new[\"Sea_Surface_Temp_C_South\"] > 0.5).astype(int)\n",
        "    df_new[\"Melt_Index_South\"] = df_new[\"Sea_Surface_Temp_C_South\"].clip(lower=0, upper=4) / 4\n",
        "\n",
        "    # Validate before updating SQLite\n",
        "    expected_columns = [\"Year\", \"Quarter\", \"Sea_Surface_Temp_C_South\", \"Melt_Active_South\", \"Melt_Index_South\"]\n",
        "    dtypes = {\"Year\": int, \"Quarter\": str, \"Sea_Surface_Temp_C_South\": float, \"Melt_Active_South\": int, \"Melt_Index_South\": float}\n",
        "    validate_dataframe(df_new, expected_columns, dtypes)\n",
        "\n",
        "    # Generate DML statements for insertion\n",
        "    dml_statements = []\n",
        "    for _, row in df_new.iterrows():\n",
        "        dml_statements.append(\n",
        "            f\"INSERT INTO sst_south (Year, Quarter, Sea_Surface_Temp_C_South, Melt_Active_South, Melt_Index_South) VALUES \"\n",
        "            f\"({row['Year']}, '{row['Quarter']}', {row['Sea_Surface_Temp_C_South']}, {row['Melt_Active_South']}, {row['Melt_Index_South']})\"\n",
        "        )\n",
        "\n",
        "    # Append DML statements to dml_populate.sql\n",
        "    with open('dml_populate.sql', 'a') as f:\n",
        "        f.write(\"\\n-- Update for sst_south\\n\")\n",
        "        f.write(\"\\n\".join(dml_statements) + \";\\n\")\n",
        "\n",
        "    # Execute the DML script\n",
        "    execute_sql_script('dml_populate.sql')\n",
        "    print(\"Updated sst_south table with new data\")\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error fetching new SST South data: {e}\")\n",
        "\n",
        "# Final display\n",
        "print(\"Updated SST South DataFrame:\")\n",
        "df_updated = pd.read_sql_query(\"SELECT * FROM sst_south WHERE Year = ? AND Quarter = ?\", conn, params=(next_year, next_quarter))\n",
        "display(df_updated)"
      ],
      "metadata": {
        "id": "2cqv3IBcVrKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UPDATE FOREIGN CATCH\n",
        "\n",
        "# Determine the most recent data point in the foreign_catch table\n",
        "cursor.execute(\"SELECT MAX(Year), Quarter FROM foreign_catch WHERE Year = (SELECT MAX(Year) FROM foreign_catch)\")\n",
        "result = cursor.fetchone()\n",
        "if result and result[0] is not None:\n",
        "    latest_year, latest_quarter = result\n",
        "    print(f\"Latest data point: {latest_year} {latest_quarter}\")\n",
        "else:\n",
        "    latest_year, latest_quarter = 2010, \"Q4\"  # Fallback to start of range\n",
        "    print(\"No data found in foreign_catch, starting from 2010 Q4\")\n",
        "\n",
        "# Determine the next quarter to fetch\n",
        "quarter_order = [\"Q1\", \"Q2\", \"Q3\", \"Q4\"]\n",
        "next_quarter_idx = (quarter_order.index(latest_quarter) + 1) % 4\n",
        "next_year = latest_year if next_quarter_idx != 0 else latest_year + 1\n",
        "next_quarter = quarter_order[next_quarter_idx]\n",
        "print(f\"Fetching data for: {next_year} {next_quarter}\")\n",
        "\n",
        "# Fetch new data from the API\n",
        "url = \"https://bank.stat.gl:443/api/v1/en/Greenland/FI/FI10/FIX008.px\"\n",
        "query = {\n",
        "    \"query\": [\n",
        "        {\"code\": \"nation\", \"selection\": {\"filter\": \"item\", \"values\": [\"Foreign\"]}},\n",
        "        {\"code\": \"unit\", \"selection\": {\"filter\": \"item\", \"values\": [\"Ton\"]}},\n",
        "        {\"code\": \"time\", \"selection\": {\"filter\": \"item\", \"values\": [str(next_year)]}},\n",
        "        {\"code\": \"quarter\", \"selection\": {\"filter\": \"item\", \"values\": [str(next_quarter_idx + 1)]}}\n",
        "    ],\n",
        "    \"response\": {\"format\": \"json-stat2\"}\n",
        "}\n",
        "try:\n",
        "    response = requests.post(url, json=query, timeout=30)\n",
        "    response.raise_for_status()\n",
        "    dataset = pyjstat.Dataset.read(response.text)\n",
        "    df = dataset.write('dataframe')\n",
        "    print(\"Data successfully retrieved and converted to DataFrame!\")\n",
        "\n",
        "    # Clean DataFrame\n",
        "    df_new = df.copy()\n",
        "    df_new.drop(columns=['nation'], inplace=True)\n",
        "    df_new.rename(columns={\n",
        "        \"time\": \"Year\",\n",
        "        \"quarter\": \"Quarter\",\n",
        "        \"unit\": \"Unit\",\n",
        "        \"value\": \"Foreign_Catch\"\n",
        "    }, inplace=True)\n",
        "    df_new[\"Quarter\"] = df_new[\"Quarter\"].str.replace(\"Quarter \", \"Q\")\n",
        "    df_new[\"Quarter\"] = pd.Categorical(df_new[\"Quarter\"], categories=quarter_order, ordered=True)\n",
        "    df_new = df_new[[\"Year\", \"Quarter\", \"Unit\", \"Foreign_Catch\"]]\n",
        "    df_new[\"Year\"] = df_new[\"Year\"].astype(int)\n",
        "\n",
        "    # Validate before updating SQLite\n",
        "    expected_columns = [\"Year\", \"Quarter\", \"Unit\", \"Foreign_Catch\"]\n",
        "    dtypes = {\"Year\": int, \"Quarter\": str, \"Unit\": str, \"Foreign_Catch\": int}\n",
        "    validate_dataframe(df_new, expected_columns, dtypes)\n",
        "\n",
        "    # Generate DML statements for insertion\n",
        "    dml_statements = []\n",
        "    for _, row in df_new.iterrows():\n",
        "        dml_statements.append(\n",
        "            f\"INSERT INTO foreign_catch (Year, Quarter, Unit, Foreign_Catch) VALUES \"\n",
        "            f\"({row['Year']}, '{row['Quarter']}', '{row['Unit']}', {row['Foreign_Catch']})\"\n",
        "        )\n",
        "\n",
        "    # Append DML statements to dml_populate.sql\n",
        "    with open('dml_populate.sql', 'a') as f:\n",
        "        f.write(\"\\n-- Update for foreign_catch\\n\")\n",
        "        f.write(\"\\n\".join(dml_statements) + \";\\n\")\n",
        "\n",
        "    # Execute the DML script\n",
        "    execute_sql_script('dml_populate.sql')\n",
        "    print(\"Updated foreign_catch table with new data\")\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error fetching new Foreign Catch data: {e}\")\n",
        "\n",
        "# Final display\n",
        "print(\"Updated Foreign Catch DataFrame:\")\n",
        "df_updated = pd.read_sql_query(\"SELECT * FROM foreign_catch WHERE Year = ? AND Quarter = ?\", conn, params=(next_year, next_quarter))\n",
        "display(df_updated)"
      ],
      "metadata": {
        "id": "fefe0sgOxKl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UPDATE ICE MELT SST\n",
        "\n",
        "# Determine the most recent data point in the ice_melt_sst table\n",
        "cursor.execute(\"SELECT MAX(Year), Quarter FROM ice_melt_sst WHERE Year = (SELECT MAX(Year) FROM ice_melt_sst)\")\n",
        "result = cursor.fetchone()\n",
        "if result and result[0] is not None:\n",
        "    latest_year, latest_quarter = result\n",
        "    print(f\"Latest data point: {latest_year} {latest_quarter}\")\n",
        "else:\n",
        "    latest_year, latest_quarter = 2010, \"Q4\"  # Fallback to start of range\n",
        "    print(\"No data found in ice_melt_sst, starting from 2010 Q4\")\n",
        "\n",
        "# Determine the next quarter to fetch\n",
        "quarter_order = [\"Q1\", \"Q2\", \"Q3\", \"Q4\"]\n",
        "next_quarter_idx = (quarter_order.index(latest_quarter) + 1) % 4\n",
        "next_year = latest_year if next_quarter_idx != 0 else latest_year + 1\n",
        "next_quarter = quarter_order[next_quarter_idx]\n",
        "print(f\"Computing data for: {next_year} {next_quarter}\")\n",
        "\n",
        "# Fetch the latest SST data for East and West Greenland\n",
        "df_sst_east = pd.read_sql_query(\"SELECT * FROM sst_east WHERE Year = ? AND Quarter = ?\", conn, params=(next_year, next_quarter))\n",
        "df_sst_west = pd.read_sql_query(\"SELECT * FROM sst_west WHERE Year = ? AND Quarter = ?\", conn, params=(next_year, next_quarter))\n",
        "\n",
        "if not df_sst_east.empty and not df_sst_west.empty:\n",
        "    # Normalize SST for the formula (assuming SST ranges from -2 to 20°C, map to 0–1)\n",
        "    sst_east_norm = (df_sst_east[\"Sea_Surface_Temp_C_East\"].iloc[0] + 2) / 22\n",
        "    sst_west_norm = (df_sst_west[\"Sea_Surface_Temp_C_West\"].iloc[0] + 2) / 22\n",
        "\n",
        "    # Compute Ice Melt Rate as a weighted average of Melt Index and normalized SST\n",
        "    ice_melt_rate_east = (0.7 * df_sst_east[\"Melt_Index_East\"].iloc[0] + 0.3 * sst_east_norm)\n",
        "    ice_melt_rate_west = (0.7 * df_sst_west[\"Melt_Index_West\"].iloc[0] + 0.3 * sst_west_norm)\n",
        "\n",
        "    # Create DataFrame\n",
        "    df_new = pd.DataFrame({\n",
        "        \"Year\": [next_year],\n",
        "        \"Quarter\": [next_quarter],\n",
        "        \"Ice_Melt_Rate_East\": [ice_melt_rate_east],\n",
        "        \"Ice_Melt_Rate_West\": [ice_melt_rate_west],\n",
        "        \"SST_East\": [df_sst_east[\"Sea_Surface_Temp_C_East\"].iloc[0]],\n",
        "        \"SST_West\": [df_sst_west[\"Sea_Surface_Temp_C_West\"].iloc[0]]\n",
        "    })\n",
        "\n",
        "    # Validate before updating SQLite\n",
        "    expected_columns = [\"Year\", \"Quarter\", \"Ice_Melt_Rate_East\", \"Ice_Melt_Rate_West\", \"SST_East\", \"SST_West\"]\n",
        "    dtypes = {\"Year\": int, \"Quarter\": str, \"Ice_Melt_Rate_East\": float, \"Ice_Melt_Rate_West\": float, \"SST_East\": float, \"SST_West\": float}\n",
        "    validate_dataframe(df_new, expected_columns, dtypes)\n",
        "\n",
        "    # Generate DML statements for insertion\n",
        "    dml_statements = []\n",
        "    for _, row in df_new.iterrows():\n",
        "        dml_statements.append(\n",
        "            f\"INSERT INTO ice_melt_sst (Year, Quarter, Ice_Melt_Rate_East, Ice_Melt_Rate_West, SST_East, SST_West) VALUES \"\n",
        "            f\"({row['Year']}, '{row['Quarter']}', {row['Ice_Melt_Rate_East']}, {row['Ice_Melt_Rate_West']}, {row['SST_East']}, {row['SST_West']})\"\n",
        "        )\n",
        "\n",
        "    # Append DML statements to dml_populate.sql\n",
        "    with open('dml_populate.sql', 'a') as f:\n",
        "        f.write(\"\\n-- Update for ice_melt_sst\\n\")\n",
        "        f.write(\"\\n\".join(dml_statements) + \";\\n\")\n",
        "\n",
        "    # Execute the DML script\n",
        "    execute_sql_script('dml_populate.sql')\n",
        "    print(\"Updated ice_melt_sst table with new data\")\n",
        "else:\n",
        "    print(\"No new data available for ice_melt_sst (requires updated sst_east and sst_west data)\")\n",
        "\n",
        "# Final display\n",
        "print(\"Updated Ice Melt SST DataFrame:\")\n",
        "df_updated = pd.read_sql_query(\"SELECT * FROM ice_melt_sst WHERE Year = ? AND Quarter = ?\", conn, params=(next_year, next_quarter))\n",
        "display(df_updated)"
      ],
      "metadata": {
        "id": "CbgbitwqxPty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Close the database connection\n",
        "conn.close()\n",
        "print(\"Database connection closed.\")"
      ],
      "metadata": {
        "id": "vu-0riJCVuEJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}