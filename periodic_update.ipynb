{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMX8yCXwYfFTan77cP0c51Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ccspen21/greenland-fishery-nowcast-2025/blob/main/periodic_update.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kg2LslY3Up8a"
      },
      "outputs": [],
      "source": [
        "!pip install requests pandas pyjstat\n",
        "import os\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "import requests\n",
        "from pyjstat import pyjstat\n",
        "from urllib.parse import quote\n",
        "from io import StringIO\n",
        "from IPython.display import display\n",
        "from google.colab import drive\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define database path\n",
        "DB_PATH = '/content/drive/MyDrive/greenland_fishery.db'\n",
        "\n",
        "# validate DataFrame\n",
        "def validate_dataframe(df, expected_columns, dtypes):\n",
        "    if df.empty:\n",
        "        raise ValueError(\"DataFrame is empty, no rows found.\")\n",
        "    if not all(col in df.columns for col in expected_columns):\n",
        "        raise ValueError(f\"DataFrame missing expected columns: {expected_columns}\")\n",
        "    for col, dtype in dtypes.items():\n",
        "        if col in df.columns:\n",
        "            if dtype == int:\n",
        "                df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)\n",
        "            else:\n",
        "                df[col] = df[col].astype(dtype)\n",
        "    if df.isnull().any().any():\n",
        "        raise ValueError(f\"DataFrame contains NaN values: {df.head()}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to SQLite database\n",
        "conn = sqlite3.connect(DB_PATH)\n",
        "cursor = conn.cursor()\n",
        "print(f\"Connected to SQLite database at {DB_PATH}\")\n",
        "\n",
        "# execute SQL scripts\n",
        "def execute_sql_script(file_path):\n",
        "    try:\n",
        "        with open(file_path, 'r') as file:\n",
        "            sql_script = file.read()\n",
        "        cursor.executescript(sql_script)\n",
        "        conn.commit()\n",
        "        print(f\"Successfully executed SQL script: {file_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error executing SQL script {file_path}: {e}\")\n",
        "        raise\n",
        "\n",
        "# check for existing data\n",
        "def check_existing_data(table_name, year, quarter):\n",
        "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table' AND name=?\", (table_name,))\n",
        "    if not cursor.fetchone():\n",
        "        print(f\"Table {table_name} does not exist.\")\n",
        "        return False\n",
        "    query = f\"SELECT COUNT(*) FROM {table_name} WHERE Year = ? AND Quarter = ?\"\n",
        "    cursor.execute(query, (year, quarter))\n",
        "    count = cursor.fetchone()[0]\n",
        "    return count > 0\n",
        "\n",
        "# Function to get latest data point from table\n",
        "def get_latest_db_data(table_name):\n",
        "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table' AND name=?\", (table_name,))\n",
        "    if not cursor.fetchone():\n",
        "        print(f\"Table {table_name} does not exist, assuming no data.\")\n",
        "        return 2010, \"Q4\"\n",
        "    query = f\"SELECT MAX(Year), Quarter FROM {table_name} WHERE Year = (SELECT MAX(Year) FROM {table_name})\"\n",
        "    cursor.execute(query)\n",
        "    result = cursor.fetchone()\n",
        "    return result if result and result[0] else (2010, \"Q4\")"
      ],
      "metadata": {
        "id": "XsZIYHGVVYxT",
        "outputId": "8ac8f5c7-c2ff-44c5-c211-3a09d968d94b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connected to SQLite database at greenland_fishery.db\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function to validate DataFrame against schema\n",
        "def validate_dataframe(df, expected_columns, dtypes):\n",
        "    if not all(col in df.columns for col in expected_columns):\n",
        "        raise ValueError(f\"DataFrame missing expected columns: {expected_columns}\")\n",
        "    for col, dtype in dtypes.items():\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col].astype(dtype)\n",
        "    if df.isnull().any().any():\n",
        "        raise ValueError(f\"DataFrame contains NaN values: {df.head()}\")"
      ],
      "metadata": {
        "id": "u7xATA1NVh-d"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 3: UPDATE TOTAL CATCH\n",
        "# Define quarter order\n",
        "quarter_order = [\"Q1\", \"Q2\", \"Q3\", \"Q4\"]\n",
        "\n",
        "# Get latest data point from database\n",
        "latest_year, latest_quarter = get_latest_db_data('total_catch')\n",
        "print(f\"Latest database data point: {latest_year} {latest_quarter}\")\n",
        "\n",
        "# Check API for latest available data\n",
        "url = \"https://bank.stat.gl:443/api/v1/en/Greenland/FI/FI10/FIX008.px\"\n",
        "api_year, api_quarter = get_latest_quarter_from_api(url, nation=\"GRL\")\n",
        "print(f\"Latest API data point: {api_year} {api_quarter}\")\n",
        "\n",
        "# Determine if update is needed\n",
        "update_needed = False\n",
        "if api_year and api_quarter:\n",
        "    db_idx = latest_year * 4 + quarter_order.index(latest_quarter)\n",
        "    api_idx = api_year * 4 + quarter_order.index(api_quarter)\n",
        "    if api_idx > db_idx:\n",
        "        update_needed = True\n",
        "        next_year, next_quarter = api_year, api_quarter\n",
        "    else:\n",
        "        print(\"No new data available for total_catch.\")\n",
        "else:\n",
        "    print(\"Could not fetch latest quarter from API, skipping total_catch update.\")\n",
        "\n",
        "if update_needed and not check_existing_data('total_catch', next_year, next_quarter):\n",
        "    # Fetch new data\n",
        "    query = {\n",
        "        \"query\": [\n",
        "            {\"code\": \"nation\", \"selection\": {\"filter\": \"item\", \"values\": [\"GRL\"]}},\n",
        "            {\"code\": \"unit\", \"selection\": {\"filter\": \"item\", \"values\": [\"Ton\"]}},\n",
        "            {\"code\": \"time\", \"selection\": {\"filter\": \"item\", \"values\": [str(next_year)]}},\n",
        "            {\"code\": \"quarter\", \"selection\": {\"filter\": \"item\", \"values\": [str(quarter_order.index(next_quarter) + 1)]}}\n",
        "        ],\n",
        "        \"response\": {\"format\": \"json-stat2\"}\n",
        "    }\n",
        "    try:\n",
        "        response = fetch_with_retries(url, max_retries=3, timeout=60, method='post', json=query)\n",
        "        dataset = pyjstat.Dataset.read(response.text)\n",
        "        df = dataset.write('dataframe')\n",
        "        print(\"Data successfully retrieved and converted to DataFrame!\")\n",
        "\n",
        "        # Clean DataFrame\n",
        "        df_new = df.copy()\n",
        "        df_new.drop(columns=['nation'], inplace=True)\n",
        "        df_new.rename(columns={\n",
        "            \"time\": \"Year\",\n",
        "            \"quarter\": \"Quarter\",\n",
        "            \"unit\": \"Unit\",\n",
        "            \"value\": \"Total_Catch\"\n",
        "        }, inplace=True)\n",
        "        df_new[\"Quarter\"] = df_new[\"Quarter\"].str.replace(\"Quarter \", \"Q\")\n",
        "        df_new[\"Quarter\"] = pd.Categorical(df_new[\"Quarter\"], categories=quarter_order, ordered=True)\n",
        "        df_new = df_new[[\"Year\", \"Quarter\", \"Unit\", \"Total_Catch\"]]\n",
        "        df_new[\"Year\"] = df_new[\"Year\"].astype(int)\n",
        "\n",
        "        # Validate\n",
        "        expected_columns = [\"Year\", \"Quarter\", \"Unit\", \"Total_Catch\"]\n",
        "        dtypes = {\"Year\": int, \"Quarter\": str, \"Unit\": str, \"Total_Catch\": int}\n",
        "        validate_dataframe(df_new, expected_columns, dtypes)\n",
        "\n",
        "        # Generate DML statements\n",
        "        dml_statements = []\n",
        "        for _, row in df_new.iterrows():\n",
        "            dml_statements.append(\n",
        "                f\"INSERT INTO total_catch (Year, Quarter, Unit, Total_Catch) VALUES \"\n",
        "                f\"({row['Year']}, '{row['Quarter']}', '{row['Unit']}', {row['Total_Catch']})\"\n",
        "            )\n",
        "\n",
        "        # Append DML statements\n",
        "        with open('/content/drive/MyDrive/dml_populate.sql', 'a') as f:\n",
        "            f.write(\"\\n-- Update for total_catch\\n\")\n",
        "            f.write(\"\\n\".join(dml_statements) + \";\\n\")\n",
        "\n",
        "        # Execute DML\n",
        "        execute_sql_script('/content/drive/MyDrive/dml_populate.sql')\n",
        "        print(\"Updated total_catch table with new data\")\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching new Total Catch data: {e}\")\n",
        "\n",
        "# Display updated data\n",
        "print(\"Updated Total Catch DataFrame:\")\n",
        "df_updated = pd.read_sql_query(\"SELECT * FROM total_catch WHERE Year = ? AND Quarter = ?\", conn, params=(next_year, next_quarter))\n",
        "display(df_updated)"
      ],
      "metadata": {
        "id": "wbDAgN3LVift",
        "outputId": "2d83af5b-9a0f-489d-ab16-7da8b1075600",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OperationalError",
          "evalue": "no such table: total",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-bdfdf6e00519>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Determine the most recent data point in the total_catch table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SELECT MAX(Year), Quarter FROM total catch WHERE Year = (SELECT MAX(Year) FROM total catch)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetchone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOperationalError\u001b[0m: no such table: total"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 5: UPDATE FISH EXPORTS\n",
        "# Get latest data point from database\n",
        "latest_year, latest_quarter = get_latest_db_data('fish_exports')\n",
        "print(f\"Latest database data point: {latest_year} {latest_quarter}\")\n",
        "\n",
        "# Check API for latest available data\n",
        "url = \"https://bank.stat.gl:443/api/v1/en/Greenland/BE/BE80/BEXSTA22.px\"\n",
        "api_year, api_quarter = get_latest_quarter_from_api(url, unit=\"Mill. kr.\")\n",
        "print(f\"Latest API data point: {api_year} {api_quarter}\")\n",
        "\n",
        "# Determine if update is needed\n",
        "update_needed = False\n",
        "if api_year and api_quarter:\n",
        "    db_idx = latest_year * 4 + quarter_order.index(latest_quarter)\n",
        "    api_idx = api_year * 4 + quarter_order.index(api_quarter)\n",
        "    if api_idx > db_idx:\n",
        "        update_needed = True\n",
        "        next_year, next_quarter = api_year, api_quarter\n",
        "    else:\n",
        "        print(\"No new data available for fish_exports.\")\n",
        "else:\n",
        "    print(\"Could not fetch latest quarter from API, skipping fish_exports update.\")\n",
        "\n",
        "if update_needed and not check_existing_data('fish_exports', next_year, next_quarter):\n",
        "    # Fetch new data\n",
        "    query = {\n",
        "        \"query\": [\n",
        "            {\"code\": \"unit\", \"selection\": {\"filter\": \"item\", \"values\": [\"Mill. kr.\"]}},\n",
        "            {\"code\": \"time\", \"selection\": {\"filter\": \"item\", \"values\": [str(next_year)]}},\n",
        "            {\"code\": \"quarter\", \"selection\": {\"filter\": \"item\", \"values\": [str(quarter_order.index(next_quarter) + 1)]}}\n",
        "        ],\n",
        "        \"response\": {\"format\": \"json-stat2\"}\n",
        "    }\n",
        "    try:\n",
        "        response = fetch_with_retries(url, max_retries=3, timeout=60, method='post', json=query)\n",
        "        dataset = pyjstat.Dataset.read(response.text)\n",
        "        df = dataset.write('dataframe')\n",
        "        print(\"Data successfully retrieved and converted to DataFrame!\")\n",
        "\n",
        "        # Clean DataFrame\n",
        "        df_new = df.copy()\n",
        "        df_new.rename(columns={\n",
        "            \"time\": \"Year\",\n",
        "            \"quarter\": \"Quarter\",\n",
        "            \"value\": \"Fish_Export_Value_Million_Kr\"\n",
        "        }, inplace=True)\n",
        "        df_new[\"Quarter\"] = df_new[\"Quarter\"].str.replace(\"Quarter \", \"Q\")\n",
        "        df_new[\"Quarter\"] = pd.Categorical(df_new[\"Quarter\"], categories=quarter_order, ordered=True)\n",
        "        df_new = df_new[[\"Year\", \"Quarter\", \"Fish_Export_Value_Million_Kr\"]]\n",
        "        df_new[\"Year\"] = df_new[\"Year\"].astype(int)\n",
        "\n",
        "        # Validate\n",
        "        expected_columns = [\"Year\", \"Quarter\", \"Fish_Export_Value_Million_Kr\"]\n",
        "        dtypes = {\"Year\": int, \"Quarter\": str, \"Fish_Export_Value_Million_Kr\": int}\n",
        "        validate_dataframe(df_new, expected_columns, dtypes)\n",
        "\n",
        "        # Generate DML statements\n",
        "        dml_statements = []\n",
        "        for _, row in df_new.iterrows():\n",
        "            dml_statements.append(\n",
        "                f\"INSERT INTO fish_exports (Year, Quarter, Fish_Export_Value_Million_Kr) VALUES \"\n",
        "                f\"({row['Year']}, '{row['Quarter']}', {row['Fish_Export_Value_Million_Kr']})\"\n",
        "            )\n",
        "\n",
        "        # Append DML statements\n",
        "        with open('/content/drive/MyDrive/dml_populate.sql', 'a') as f:\n",
        "            f.write(\"\\n-- Update for fish_exports\\n\")\n",
        "            f.write(\"\\n\".join(dml_statements) + \";\\n\")\n",
        "\n",
        "        # Execute DML\n",
        "        execute_sql_script('/content/drive/MyDrive/dml_populate.sql')\n",
        "        print(\"Updated fish_exports table with new data\")\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching new Fish Exports data: {e}\")\n",
        "\n",
        "# Display updated data\n",
        "print(\"Updated Fish Exports DataFrame:\")\n",
        "df_updated = pd.read_sql_query(\"SELECT * FROM fish_exports WHERE Year = ? AND Quarter = ?\", conn, params=(next_year, next_quarter))\n",
        "display(df_updated)"
      ],
      "metadata": {
        "id": "uPPooxNkEA4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  UPDATE FOREIGN CATCH\n",
        "# Get latest data point from database\n",
        "latest_year, latest_quarter = get_latest_db_data('foreign_catch')\n",
        "print(f\"Latest database data point: {latest_year} {latest_quarter}\")\n",
        "\n",
        "# Check API for latest available data\n",
        "api_year, api_quarter = get_latest_quarter_from_api(url, nation=\"UDL\")\n",
        "print(f\"Latest API data point: {api_year} {api_quarter}\")\n",
        "\n",
        "# Determine if update is needed\n",
        "update_needed = False\n",
        "if api_year and api_quarter:\n",
        "    db_idx = latest_year * 4 + quarter_order.index(latest_quarter)\n",
        "    api_idx = api_year * 4 + quarter_order.index(api_quarter)\n",
        "    if api_idx > db_idx:\n",
        "        update_needed = True\n",
        "        next_year, next_quarter = api_year, api_quarter\n",
        "    else:\n",
        "        print(\"No new data available for foreign_catch.\")\n",
        "else:\n",
        "    print(\"Could not fetch latest quarter from API, skipping foreign_catch update.\")\n",
        "\n",
        "if update_needed and not check_existing_data('foreign_catch', next_year, next_quarter):\n",
        "    # Fetch new data\n",
        "    query = {\n",
        "        \"query\": [\n",
        "            {\"code\": \"nation\", \"selection\": {\"filter\": \"item\", \"values\": [\"UDL\"]}},\n",
        "            {\"code\": \"unit\", \"selection\": {\"filter\": \"item\", \"values\": [\"Ton\"]}},\n",
        "            {\"code\": \"time\", \"selection\": {\"filter\": \"item\", \"values\": [str(next_year)]}},\n",
        "            {\"code\": \"quarter\", \"selection\": {\"filter\": \"item\", \"values\": [str(quarter_order.index(next_quarter) + 1)]}}\n",
        "        ],\n",
        "        \"response\": {\"format\": \"json-stat2\"}\n",
        "    }\n",
        "    try:\n",
        "        response = fetch_with_retries(url, max_retries=3, timeout=60, method='post', json=query)\n",
        "        dataset = pyjstat.Dataset.read(response.text)\n",
        "        df = dataset.write('dataframe')\n",
        "        print(\"Data successfully retrieved and converted to DataFrame!\")\n",
        "\n",
        "        # Clean DataFrame\n",
        "        df_new = df.copy()\n",
        "        df_new.drop(columns=['nation'], inplace=True)\n",
        "        df_new.rename(columns={\n",
        "            \"time\": \"Year\",\n",
        "            \"quarter\": \"Quarter\",\n",
        "            \"unit\": \"Unit\",\n",
        "            \"value\": \"Foreign_Catch\"\n",
        "        }, inplace=True)\n",
        "        df_new[\"Quarter\"] = df_new[\"Quarter\"].str.replace(\"Quarter \", \"Q\")\n",
        "        df_new[\"Quarter\"] = pd.Categorical(df_new[\"Quarter\"], categories=quarter_order, ordered=True)\n",
        "        df_new = df_new[[\"Year\", \"Quarter\", \"Unit\", \"Foreign_Catch\"]]\n",
        "        df_new[\"Year\"] = df_new[\"Year\"].astype(int)\n",
        "\n",
        "        # Validate\n",
        "        expected_columns = [\"Year\", \"Quarter\", \"Unit\", \"Foreign_Catch\"]\n",
        "        dtypes = {\"Year\": int, \"Quarter\": str, \"Unit\": str, \"Foreign_Catch\": int}\n",
        "        validate_dataframe(df_new, expected_columns, dtypes)\n",
        "\n",
        "        # Generate DML statements\n",
        "        dml_statements = []\n",
        "        for _, row in df_new.iterrows():\n",
        "            dml_statements.append(\n",
        "                f\"INSERT INTO foreign_catch (Year, Quarter, Unit, Foreign_Catch) VALUES \"\n",
        "                f\"({row['Year']}, '{row['Quarter']}', '{row['Unit']}', {row['Foreign_Catch']})\"\n",
        "            )\n",
        "\n",
        "        # Append DML statements\n",
        "        with open('/content/drive/MyDrive/dml_populate.sql', 'a') as f:\n",
        "            f.write(\"\\n-- Update for foreign_catch\\n\")\n",
        "            f.write(\"\\n\".join(dml_statements) + \";\\n\")\n",
        "\n",
        "        # Execute DML\n",
        "        execute_sql_script('/content/drive/MyDrive/dml_populate.sql')\n",
        "        print(\"Updated foreign_catch table with new data\")\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching new Foreign Catch data: {e}\")\n",
        "\n",
        "# Display updated data\n",
        "print(\"Updated Foreign Catch DataFrame:\")\n",
        "df_updated = pd.read_sql_query(\"SELECT * FROM foreign_catch WHERE Year = ? AND Quarter = ?\", conn, params=(next_year, next_quarter))\n",
        "display(df_updated)"
      ],
      "metadata": {
        "id": "Gxopz6AnVoaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ERDDAP SETUP\n",
        "\n",
        "# api retry\n",
        "def fetch_with_retries(url, max_retries=3, timeout=60, method='get', json=None):\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            if method == 'get':\n",
        "                response = requests.get(url, timeout=timeout)\n",
        "            else:\n",
        "                response = requests.post(url, json=json, timeout=timeout)\n",
        "            response.raise_for_status()\n",
        "            return response\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Attempt {attempt+1} failed: {e}\")\n",
        "            if attempt + 1 == max_retries:\n",
        "                raise\n",
        "            time.sleep(2 ** attempt)\n",
        "\n",
        "# Helper function to get latest available quarter from bank.stat.gl\n",
        "def get_latest_quarter_from_api(url, nation=None, unit=\"Ton\"):\n",
        "    query = {\n",
        "        \"query\": [\n",
        "            {\"code\": \"time\", \"selection\": {\"filter\": \"all\", \"values\": [\"*\"]}},\n",
        "            {\"code\": \"quarter\", \"selection\": {\"filter\": \"all\", \"values\": [\"*\"]}}\n",
        "        ],\n",
        "        \"response\": {\"format\": \"json-stat2\"}\n",
        "    }\n",
        "    if nation:\n",
        "        query[\"query\"].insert(0, {\"code\": \"nation\", \"selection\": {\"filter\": \"item\", \"values\": [nation]}})\n",
        "    query[\"query\"].append({\"code\": \"unit\", \"selection\": {\"filter\": \"item\", \"values\": [unit]}})\n",
        "    try:\n",
        "        response = fetch_with_retries(url, max_retries=3, timeout=60, method='post', json=query)\n",
        "        dataset = pyjstat.Dataset.read(response.text)\n",
        "        df = dataset.write('dataframe')\n",
        "        df[\"time\"] = df[\"time\"].astype(int)\n",
        "        latest_year = df[\"time\"].max()\n",
        "        latest_quarter = df[df[\"time\"] == latest_year][\"quarter\"].max().replace(\"Quarter \", \"Q\")\n",
        "        return latest_year, latest_quarter\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching latest quarter: {e}\")\n",
        "        return None, None\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QfQ64dyXCp_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 6: UPDATE WEST GREENLAND SST\n",
        "# Define quarter to months mapping\n",
        "quarter_to_months = {\n",
        "    \"Q1\": (\"01-01\", \"03-31\"),\n",
        "    \"Q2\": (\"04-01\", \"06-30\"),\n",
        "    \"Q3\": (\"07-01\", \"09-30\"),\n",
        "    \"Q4\": (\"10-01\", \"12-31\")\n",
        "}\n",
        "\n",
        "# Degree to ERDDAP grid index conversion\n",
        "def deg_to_index_lat(lat): return int(round((lat + 90) / 0.25))\n",
        "def deg_to_index_lon(lon): return int(round((lon + 180) / 0.25))\n",
        "\n",
        "# Define bounding box for West Greenland\n",
        "bbox_deg_west = {\n",
        "    'lat_min': 65.0,\n",
        "    'lat_max': 70.0,\n",
        "    'lon_min': -55.0,\n",
        "    'lon_max': -50.0\n",
        "}\n",
        "\n",
        "# Convert to grid indices\n",
        "bbox_idx_west = {\n",
        "    'lat_min': deg_to_index_lat(bbox_deg_west['lat_min']),\n",
        "    'lat_max': deg_to_index_lat(bbox_deg_west['lat_max']),\n",
        "    'lon_min': deg_to_index_lon(bbox_deg_west['lon_min']),\n",
        "    'lon_max': deg_to_index_lon(bbox_deg_west['lon_max'])\n",
        "}\n",
        "\n",
        "# Get latest data point from database\n",
        "latest_year, latest_quarter = get_latest_db_data('sst_west')\n",
        "print(f\"Latest database data point: {latest_year} {latest_quarter}\")\n",
        "\n",
        "# Determine next quarter\n",
        "quarter_idx = (quarter_order.index(latest_quarter) + 1) % 4\n",
        "next_year = latest_year if quarter_idx != 0 else latest_year + 1\n",
        "next_quarter = quarter_order[quarter_idx]\n",
        "\n",
        "# Check if enough time has passed\n",
        "current_date = datetime.now()\n",
        "quarter_end_dates = {\n",
        "    \"Q1\": datetime(next_year, 3, 31),\n",
        "    \"Q2\": datetime(next_year, 6, 30),\n",
        "    \"Q3\": datetime(next_year, 9, 30),\n",
        "    \"Q4\": datetime(next_year, 12, 31)\n",
        "}\n",
        "if current_date <= quarter_end_dates[next_quarter]:\n",
        "    print(f\"Current date {current_date.date()} is before {next_quarter} end ({quarter_end_dates[next_quarter].date()}), skipping sst_west update.\")\n",
        "else:\n",
        "    print(f\"Fetching data for: {next_year} {next_quarter}\")\n",
        "    if not check_existing_data('sst_west', next_year, next_quarter):\n",
        "        # Map quarter to months\n",
        "        start_month, end_month = quarter_to_months[next_quarter]\n",
        "\n",
        "        # Fetch new data\n",
        "        try:\n",
        "            base = \"https://coastwatch.pfeg.noaa.gov/erddap/griddap/ncdcOisst21Agg_LonPM180.csv?\"\n",
        "            var = \"sst\"\n",
        "            time = f\"[({next_year}-{start_month}T00:00:00Z):1:({next_year}-{end_month}T00:00:00Z)]\".replace(\" \", \"\")\n",
        "            zlev = \"[0:1:0]\"\n",
        "            lat = f\"[({bbox_idx_west['lat_min']}):1:({bbox_idx_west['lat_max']})]\"\n",
        "            lon = f\"[({bbox_idx_west['lon_min']}):1:({bbox_idx_west['lon_max']})]\"\n",
        "            query = f\"{var}{time}{zlev}{lat}{lon}\"\n",
        "            full_url = base + quote(query, safe=\":/[](),-T\")\n",
        "            print(\"Constructed URL:\", full_url)\n",
        "\n",
        "            response = fetch_with_retries(full_url, max_retries=3, timeout=60, method='get')\n",
        "            df = pd.read_csv(StringIO(response.text), skiprows=[1])\n",
        "            df = df.rename(columns={col: col.strip() for col in df.columns})\n",
        "            df = df.dropna(subset=[\"sst\"])\n",
        "\n",
        "            df[\"time\"] = pd.to_datetime(df[\"time\"])\n",
        "            df[\"Year\"] = df[\"time\"].dt.year.astype(int)\n",
        "            df[\"Quarter\"] = \"Q\" + df[\"time\"].dt.quarter.astype(str)\n",
        "\n",
        "            df_new = df.groupby(['Year', 'Quarter'])[\"sst\"].mean().reset_index()\n",
        "            df_new = df_new.rename(columns={\"sst\": \"Sea_Surface_Temp_C_West\"})\n",
        "\n",
        "            df_new[\"Melt_Active_West\"] = (df_new[\"Sea_Surface_Temp_C_West\"] > 0.5).astype(int)\n",
        "            df_new[\"Melt_Index_West\"] = df_new[\"Sea_Surface_Temp_C_West\"].clip(lower=0, upper=4) / 4\n",
        "\n",
        "            # Validate\n",
        "            expected_columns = [\"Year\", \"Quarter\", \"Sea_Surface_Temp_C_West\", \"Melt_Active_West\", \"Melt_Index_West\"]\n",
        "            dtypes = {\"Year\": int, \"Quarter\": str, \"Sea_Surface_Temp_C_West\": float, \"Melt_Active_West\": int, \"Melt_Index_West\": float}\n",
        "            validate_dataframe(df_new, expected_columns, dtypes)\n",
        "\n",
        "            # Generate DML statements\n",
        "            dml_statements = []\n",
        "            for _, row in df_new.iterrows():\n",
        "                dml_statements.append(\n",
        "                    f\"INSERT INTO sst_west (Year, Quarter, Sea_Surface_Temp_C_West, Melt_Active_West, Melt_Index_West) VALUES \"\n",
        "                    f\"({row['Year']}, '{row['Quarter']}', {row['Sea_Surface_Temp_C_West']}, {row['Melt_Active_West']}, {row['Melt_Index_West']})\"\n",
        "                )\n",
        "\n",
        "            # Append DML statements\n",
        "            with open('/content/drive/MyDrive/dml_populate.sql', 'a') as f:\n",
        "                f.write(\"\\n-- Update for sst_west\\n\")\n",
        "                f.write(\"\\n\".join(dml_statements) + \";\\n\")\n",
        "\n",
        "            # Execute DML\n",
        "            execute_sql_script('/content/drive/MyDrive/dml_populate.sql')\n",
        "            print(\"Updated sst_west table with new data\")\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Error fetching new SST West data: {e}\")\n",
        "\n",
        "# Display updated data\n",
        "print(\"Updated SST West DataFrame:\")\n",
        "df_updated = pd.read_sql_query(\"SELECT * FROM sst_west WHERE Year = ? AND Quarter = ?\", conn, params=(next_year, next_quarter))\n",
        "display(df_updated)"
      ],
      "metadata": {
        "id": "bp6KAn4AVq0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 7: UPDATE EAST GREENLAND SST\n",
        "# Define bounding box for East Greenland\n",
        "bbox_deg_east = {\n",
        "    'lat_min': 65.0,\n",
        "    'lat_max': 70.0,\n",
        "    'lon_min': -40.0,\n",
        "    'lon_max': -35.0\n",
        "}\n",
        "\n",
        "# Convert to grid indices\n",
        "bbox_idx_east = {\n",
        "    'lat_min': deg_to_index_lat(bbox_deg_east['lat_min']),\n",
        "    'lat_max': deg_to_index_lat(bbox_deg_east['lat_max']),\n",
        "    'lon_min': deg_to_index_lon(bbox_deg_east['lon_min']),\n",
        "    'lon_max': deg_to_index_lon(bbox_deg_east['lon_max'])\n",
        "}\n",
        "\n",
        "# Get latest data point from database\n",
        "latest_year, latest_quarter = get_latest_db_data('sst_east')\n",
        "print(f\"Latest database data point: {latest_year} {latest_quarter}\")\n",
        "\n",
        "# Determine next quarter\n",
        "quarter_idx = (quarter_order.index(latest_quarter) + 1) % 4\n",
        "next_year = latest_year if quarter_idx != 0 else latest_year + 1\n",
        "next_quarter = quarter_order[quarter_idx]\n",
        "\n",
        "# Check if enough time has passed\n",
        "if current_date <= quarter_end_dates[next_quarter]:\n",
        "    print(f\"Current date {current_date.date()} is before {next_quarter} end ({quarter_end_dates[next_quarter].date()}), skipping sst_east update.\")\n",
        "else:\n",
        "    print(f\"Fetching data for: {next_year} {next_quarter}\")\n",
        "    if not check_existing_data('sst_east', next_year, next_quarter):\n",
        "        # Map quarter to months\n",
        "        start_month, end_month = quarter_to_months[next_quarter]\n",
        "\n",
        "        # Fetch new data\n",
        "        try:\n",
        "            base = \"https://coastwatch.pfeg.noaa.gov/erddap/griddap/ncdcOisst21Agg_LonPM180.csv?\"\n",
        "            var = \"sst\"\n",
        "            time = f\"[({next_year}-{start_month}T00:00:00Z):1:({next_year}-{end_month}T00:00:00Z)]\".replace(\" \", \"\")\n",
        "            zlev = \"[0:1:0]\"\n",
        "            lat = f\"[({bbox_idx_east['lat_min']}):1:({bbox_idx_east['lat_max']})]\"\n",
        "            lon = f\"[({bbox_idx_east['lon_min']}):1:({bbox_idx_east['lon_max']})]\"\n",
        "            query = f\"{var}{time}{zlev}{lat}{lon}\"\n",
        "            full_url = base + quote(query, safe=\":/[](),-T\")\n",
        "            print(\"Constructed URL:\", full_url)\n",
        "\n",
        "            response = fetch_with_retries(full_url, max_retries=3, timeout=60, method='get')\n",
        "            df = pd.read_csv(StringIO(response.text), skiprows=[1])\n",
        "            df = df.rename(columns={col: col.strip() for col in df.columns})\n",
        "            df = df.dropna(subset=[\"sst\"])\n",
        "\n",
        "            df[\"time\"] = pd.to_datetime(df[\"time\"])\n",
        "            df[\"Year\"] = df[\"time\"].dt.year.astype(int)\n",
        "            df[\"Quarter\"] = \"Q\" + df[\"time\"].dt.quarter.astype(str)\n",
        "\n",
        "            df_new = df.groupby(['Year', 'Quarter'])[\"sst\"].mean().reset_index()\n",
        "            df_new = df_new.rename(columns={\"sst\": \"Sea_Surface_Temp_C_East\"})\n",
        "\n",
        "            df_new[\"Melt_Active_East\"] = (df_new[\"Sea_Surface_Temp_C_East\"] > 0.5).astype(int)\n",
        "            df_new[\"Melt_Index_East\"] = df_new[\"Sea_Surface_Temp_C_East\"].clip(lower=0, upper=4) / 4\n",
        "\n",
        "            # Validate\n",
        "            expected_columns = [\"Year\", \"Quarter\", \"Sea_Surface_Temp_C_East\", \"Melt_Active_East\", \"Melt_Index_East\"]\n",
        "            dtypes = {\"Year\": int, \"Quarter\": str, \"Sea_Surface_Temp_C_East\": float, \"Melt_Active_East\": int, \"Melt_Index_East\": float}\n",
        "            validate_dataframe(df_new, expected_columns, dtypes)\n",
        "\n",
        "            # Generate DML statements\n",
        "            dml_statements = []\n",
        "            for _, row in df_new.iterrows():\n",
        "                dml_statements.append(\n",
        "                    f\"INSERT INTO sst_east (Year, Quarter, Sea_Surface_Temp_C_East, Melt_Active_East, Melt_Index_East) VALUES \"\n",
        "                    f\"({row['Year']}, '{row['Quarter']}', {row['Sea_Surface_Temp_C_East']}, {row['Melt_Active_East']}, {row['Melt_Index_East']})\"\n",
        "                )\n",
        "\n",
        "            # Append DML statements\n",
        "            with open('/content/drive/MyDrive/dml_populate.sql', 'a') as f:\n",
        "                f.write(\"\\n-- Update for sst_east\\n\")\n",
        "                f.write(\"\\n\".join(dml_statements) + \";\\n\")\n",
        "\n",
        "            # Execute DML\n",
        "            execute_sql_script('/content/drive/MyDrive/dml_populate.sql')\n",
        "            print(\"Updated sst_east table with new data\")\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Error fetching new SST East data: {e}\")\n",
        "\n",
        "# Display updated data\n",
        "print(\"Updated SST East DataFrame:\")\n",
        "df_updated = pd.read_sql_query(\"SELECT * FROM sst_east WHERE Year = ? AND Quarter = ?\", conn, params=(next_year, next_quarter))\n",
        "display(df_updated)"
      ],
      "metadata": {
        "id": "Y90B8JbvxBPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 8: UPDATE SOUTH GREENLAND SST\n",
        "# Define bounding box for South Greenland\n",
        "bbox_deg_south = {\n",
        "    'lat_min': 60.0,\n",
        "    'lat_max': 65.0,\n",
        "    'lon_min': -45.0,\n",
        "    'lon_max': -40.0\n",
        "}\n",
        "\n",
        "# Convert to grid indices\n",
        "bbox_idx_south = {\n",
        "    'lat_min': deg_to_index_lat(bbox_deg_south['lat_min']),\n",
        "    'lat_max': deg_to_index_lat(bbox_deg_south['lat_max']),\n",
        "    'lon_min': deg_to_index_lon(bbox_deg_south['lon_min']),\n",
        "    'lon_max': deg_to_index_lon(bbox_deg_south['lon_max'])\n",
        "}\n",
        "\n",
        "# Get latest data point from database\n",
        "latest_year, latest_quarter = get_latest_db_data('sst_south')\n",
        "print(f\"Latest database data point: {latest_year} {latest_quarter}\")\n",
        "\n",
        "# Determine next quarter\n",
        "quarter_idx = (quarter_order.index(latest_quarter) + 1) % 4\n",
        "next_year = latest_year if quarter_idx != 0 else latest_year + 1\n",
        "next_quarter = quarter_order[quarter_idx]\n",
        "\n",
        "# Check if enough time has passed\n",
        "if current_date <= quarter_end_dates[next_quarter]:\n",
        "    print(f\"Current date {current_date.date()} is before {next_quarter} end ({quarter_end_dates[next_quarter].date()}), skipping sst_south update.\")\n",
        "else:\n",
        "    print(f\"Fetching data for: {next_year} {next_quarter}\")\n",
        "    if not check_existing_data('sst_south', next_year, next_quarter):\n",
        "        # Map quarter to months\n",
        "        start_month, end_month = quarter_to_months[next_quarter]\n",
        "\n",
        "        # Fetch new data\n",
        "        try:\n",
        "            base = \"https://coastwatch.pfeg.noaa.gov/erddap/griddap/ncdcOisst21Agg_LonPM180.csv?\"\n",
        "            var = \"sst\"\n",
        "            time = f\"[({next_year}-{start_month}T00:00:00Z):1:({next_year}-{end_month}T00:00:00Z)]\".replace(\" \", \"\")\n",
        "            zlev = \"[0:1:0]\"\n",
        "            lat = f\"[({bbox_idx_south['lat_min']}):1:({bbox_idx_south['lat_max']})]\"\n",
        "            lon = f\"[({bbox_idx_south['lon_min']}):1:({bbox_idx_south['lon_max']})]\"\n",
        "            query = f\"{var}{time}{zlev}{lat}{lon}\"\n",
        "            full_url = base + quote(query, safe=\":/[](),-T\")\n",
        "            print(\"Constructed URL:\", full_url)\n",
        "\n",
        "            response = fetch_with_retries(full_url, max_retries=3, timeout=60, method='get')\n",
        "            df = pd.read_csv(StringIO(response.text), skiprows=[1])\n",
        "            df = df.rename(columns={col: col.strip() for col in df.columns})\n",
        "            df = df.dropna(subset=[\"sst\"])\n",
        "\n",
        "            df[\"time\"] = pd.to_datetime(df[\"time\"])\n",
        "            df[\"Year\"] = df[\"time\"].dt.year.astype(int)\n",
        "            df[\"Quarter\"] = \"Q\" + df[\"time\"].dt.quarter.astype(str)\n",
        "\n",
        "            df_new = df.groupby(['Year', 'Quarter'])[\"sst\"].mean().reset_index()\n",
        "            df_new = df_new.rename(columns={\"sst\": \"Sea_Surface_Temp_C_South\"})\n",
        "\n",
        "            df_new[\"Melt_Active_South\"] = (df_new[\"Sea_Surface_Temp_C_South\"] > 0.5).astype(int)\n",
        "            df_new[\"Melt_Index_South\"] = df_new[\"Sea_Surface_Temp_C_South\"].clip(lower=0, upper=4) / 4\n",
        "\n",
        "            # Validate\n",
        "            expected_columns = [\"Year\", \"Quarter\", \"Sea_Surface_Temp_C_South\", \"Melt_Active_South\", \"Melt_Index_South\"]\n",
        "            dtypes = {\"Year\": int, \"Quarter\": str, \"Sea_Surface_Temp_C_South\": float, \"Melt_Active_South\": int, \"Melt_Index_South\": float}\n",
        "            validate_dataframe(df_new, expected_columns, dtypes)\n",
        "\n",
        "            # Generate DML statements\n",
        "            dml_statements = []\n",
        "            for _, row in df_new.iterrows():\n",
        "                dml_statements.append(\n",
        "                    f\"INSERT INTO sst_south (Year, Quarter, Sea_Surface_Temp_C_South, Melt_Active_South, Melt_Index_South) VALUES \"\n",
        "                    f\"({row['Year']}, '{row['Quarter']}', {row['Sea_Surface_Temp_C_South']}, {row['Melt_Active_South']}, {row['Melt_Index_South']})\"\n",
        "                )\n",
        "\n",
        "            # Append DML statements\n",
        "            with open('/content/drive/MyDrive/dml_populate.sql', 'a') as f:\n",
        "                f.write(\"\\n-- Update for sst_south\\n\")\n",
        "                f.write(\"\\n\".join(dml_statements) + \";\\n\")\n",
        "\n",
        "            # Execute DML\n",
        "            execute_sql_script('/content/drive/MyDrive/dml_populate.sql')\n",
        "            print(\"Updated sst_south table with new data\")\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Error fetching new SST South data: {e}\")\n",
        "\n",
        "# Display updated data\n",
        "print(\"Updated SST South DataFrame:\")\n",
        "df_updated = pd.read_sql_query(\"SELECT * FROM sst_south WHERE Year = ? AND Quarter = ?\", conn, params=(next_year, next_quarter))\n",
        "display(df_updated)"
      ],
      "metadata": {
        "id": "2cqv3IBcVrKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 9: UPDATE ICE MELT SST\n",
        "# Get latest data point from database\n",
        "latest_year, latest_quarter = get_latest_db_data('ice_melt_sst')\n",
        "print(f\"Latest database data point: {latest_year} {latest_quarter}\")\n",
        "\n",
        "# Determine next quarter\n",
        "quarter_idx = (quarter_order.index(latest_quarter) + 1) % 4\n",
        "next_year = latest_year if quarter_idx != 0 else latest_year + 1\n",
        "next_quarter = quarter_order[quarter_idx]\n",
        "\n",
        "# Check if enough time has passed\n",
        "if current_date <= quarter_end_dates[next_quarter]:\n",
        "    print(f\"Current date {current_date.date()} is before {next_quarter} end ({quarter_end_dates[next_quarter].date()}), skipping ice_melt_sst update.\")\n",
        "else:\n",
        "    print(f\"Computing data for: {next_year} {next_quarter}\")\n",
        "    if not check_existing_data('ice_melt_sst', next_year, next_quarter):\n",
        "        # Fetch latest SST data\n",
        "        df_sst_east = pd.read_sql_query(\"SELECT * FROM sst_east WHERE Year = ? AND Quarter = ?\", conn, params=(next_year, next_quarter))\n",
        "        df_sst_west = pd.read_sql_query(\"SELECT * FROM sst_west WHERE Year = ? AND Quarter = ?\", conn, params=(next_year, next_quarter))\n",
        "\n",
        "        if not df_sst_east.empty and not df_sst_west.empty:\n",
        "            # Normalize SST\n",
        "            sst_east_norm = (df_sst_east[\"Sea_Surface_Temp_C_East\"].iloc[0] + 2) / 22\n",
        "            sst_west_norm = (df_sst_west[\"Sea_Surface_Temp_C_West\"].iloc[0] + 2) / 22\n",
        "\n",
        "            # Compute Ice Melt Rate\n",
        "            ice_melt_rate_east = (0.7 * df_sst_east[\"Melt_Index_East\"].iloc[0] + 0.3 * sst_east_norm)\n",
        "            ice_melt_rate_west = (0.7 * df_sst_west[\"Melt_Index_West\"].iloc[0] + 0.3 * sst_west_norm)\n",
        "\n",
        "            # Create DataFrame\n",
        "            df_new = pd.DataFrame({\n",
        "                \"Year\": [next_year],\n",
        "                \"Quarter\": [next_quarter],\n",
        "                \"Ice_Melt_Rate_East\": [ice_melt_rate_east],\n",
        "                \"Ice_Melt_Rate_West\": [ice_melt_rate_west],\n",
        "                \"SST_East\": [df_sst_east[\"Sea_Surface_Temp_C_East\"].iloc[0]],\n",
        "                \"SST_West\": [df_sst_west[\"Sea_Surface_Temp_C_West\"].iloc[0]]\n",
        "            })\n",
        "\n",
        "            # Validate\n",
        "            expected_columns = [\"Year\", \"Quarter\", \"Ice_Melt_Rate_East\", \"Ice_Melt_Rate_West\", \"SST_East\", \"SST_West\"]\n",
        "            dtypes = {\"Year\": int, \"Quarter\": str, \"Ice_Melt_Rate_East\": float, \"Ice_Melt_Rate_West\": float, \"SST_East\": float, \"SST_West\": float}\n",
        "            validate_dataframe(df_new, expected_columns, dtypes)\n",
        "\n",
        "            # Generate DML statements\n",
        "            dml_statements = []\n",
        "            for _, row in df_new.iterrows():\n",
        "                dml_statements.append(\n",
        "                    f\"INSERT INTO ice_melt_sst (Year, Quarter, Ice_Melt_Rate_East, Ice_Melt_Rate_West, SST_East, SST_West) VALUES \"\n",
        "                    f\"({row['Year']}, '{row['Quarter']}', {row['Ice_Melt_Rate_East']}, {row['Ice_Melt_Rate_West']}, {row['SST_East']}, {row['SST_West']})\"\n",
        "                )\n",
        "\n",
        "            # Append DML statements\n",
        "            with open('/content/drive/MyDrive/dml_populate.sql', 'a') as f:\n",
        "                f.write(\"\\n-- Update for ice_melt_sst\\n\")\n",
        "                f.write(\"\\n\".join(dml_statements) + \";\\n\")\n",
        "\n",
        "            # Execute DML\n",
        "            execute_sql_script('/content/drive/MyDrive/dml_populate.sql')\n",
        "            print(\"Updated ice_melt_sst table with new data\")\n",
        "        else:\n",
        "            print(\"No new data available for ice_melt_sst (requires updated sst_east and sst_west data)\")\n",
        "\n",
        "# Display updated data\n",
        "print(\"Updated Ice Melt SST DataFrame:\")\n",
        "df_updated = pd.read_sql_query(\"SELECT * FROM ice_melt_sst WHERE Year = ? AND Quarter = ?\", conn, params=(next_year, next_quarter))\n",
        "display(df_updated)"
      ],
      "metadata": {
        "id": "fefe0sgOxKl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Close the database connection\n",
        "conn.close()\n",
        "print(\"Database connection closed.\")"
      ],
      "metadata": {
        "id": "vu-0riJCVuEJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}