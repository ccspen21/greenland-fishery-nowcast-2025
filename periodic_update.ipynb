{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kg2LslY3Up8a"
      },
      "outputs": [],
      "source": [
        "# Install dependencies and import libraries\n",
        "!pip install requests pandas pyjstat xarray datetime\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "import requests\n",
        "from pyjstat import pyjstat\n",
        "from IPython.display import display\n",
        "import xarray as xr\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to the SQLite database\n",
        "db_path = 'greenland_fishery.db'\n",
        "conn = sqlite3.connect(db_path)\n",
        "cursor = conn.cursor()\n",
        "print(f\"Connected to SQLite database at {db_path}\")"
      ],
      "metadata": {
        "id": "XsZIYHGVVYxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function to get the latest year and quarter from a table\n",
        "def get_latest_period(table_name, conn):\n",
        "    query = f\"SELECT MAX(Year), Quarter FROM {table_name} WHERE Year = (SELECT MAX(Year) FROM {table_name})\"\n",
        "    result = pd.read_sql_query(query, conn)\n",
        "    if not result.empty:\n",
        "        max_year = result['Year'].iloc[0]\n",
        "        max_quarter = result['Quarter'].iloc[0]\n",
        "        return max_year, max_quarter\n",
        "    return None, None"
      ],
      "metadata": {
        "id": "u7xATA1NVh-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function to determine quarters to fetch\n",
        "def quarters_to_fetch(last_year, last_quarter):\n",
        "    quarter_order = [\"Q1\", \"Q2\", \"Q3\", \"Q4\"]\n",
        "    last_idx = quarter_order.index(last_quarter)\n",
        "    years = [last_year] if last_idx < 3 else [last_year + 1]\n",
        "    quarters = [quarter_order[i] for i in range(last_idx + 1, 4)] if last_idx < 3 else [\"Q1\"]\n",
        "    if last_idx == 3:\n",
        "        years = [last_year + 1]\n",
        "        quarters = [\"Q1\"]\n",
        "    return years, quarters"
      ],
      "metadata": {
        "id": "wbDAgN3LVift"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Update Total Catch Data\n",
        "print(\"Updating Total Catch Data...\")\n",
        "last_year, last_quarter = get_latest_period(\"total_catch\", conn)\n",
        "if last_year is None:\n",
        "    print(\"No data found in total_catch table. Run setup_dataset.ipynb first.\")\n",
        "else:\n",
        "    years_to_fetch, quarters_to_fetch = quarters_to_fetch(last_year, last_quarter)\n",
        "    print(f\"Last period in total_catch: {last_year} {last_quarter}\")\n",
        "    print(f\"Fetching data for years: {years_to_fetch}, quarters: {quarters_to_fetch}\")\n",
        "\n",
        "    # Convert quarters to API format (1, 2, 3, 4)\n",
        "    quarter_mapping = {\"Q1\": \"1\", \"Q2\": \"2\", \"Q3\": \"3\", \"Q4\": \"4\"}\n",
        "    api_quarters = [quarter_mapping[q] for q in quarters_to_fetch]\n",
        "\n",
        "    # Fetch new data\n",
        "    url = \"https://bank.stat.gl:443/api/v1/en/Greenland/FI/FI10/FIX008.px\"\n",
        "    query = {\n",
        "        \"query\": [\n",
        "            {\"code\": \"nation\", \"selection\": {\"filter\": \"item\", \"values\": [\"GRL\"]}},\n",
        "            {\"code\": \"unit\", \"selection\": {\"filter\": \"item\", \"values\": [\"Ton\"]}},\n",
        "            {\"code\": \"time\", \"selection\": {\"filter\": \"item\", \"values\": [str(y) for y in years_to_fetch]}},\n",
        "            {\"code\": \"quarter\", \"selection\": {\"filter\": \"item\", \"values\": api_quarters}}\n",
        "        ],\n",
        "        \"response\": {\"format\": \"json-stat2\"}\n",
        "    }\n",
        "    response = requests.post(url, json=query)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        dataset = pyjstat.Dataset.read(response.text)\n",
        "        df = dataset.write('dataframe')\n",
        "        print(\"New Total Catch data retrieved!\")\n",
        "\n",
        "        # Clean DataFrame\n",
        "        df_clean = df.copy()\n",
        "        df_clean.drop(columns=['nation'], inplace=True)\n",
        "        df_clean.rename(columns={\n",
        "            \"time\": \"Year\",\n",
        "            \"quarter\": \"Quarter\",\n",
        "            \"unit\": \"Unit\",\n",
        "            \"value\": \"Total_Catch\"\n",
        "        }, inplace=True)\n",
        "        df_clean[\"Quarter\"] = df_clean[\"Quarter\"].str.replace(\"Quarter \", \"Q\")\n",
        "        quarter_order = [\"Q1\", \"Q2\", \"Q3\", \"Q4\"]\n",
        "        df_clean[\"Quarter\"] = pd.Categorical(df_clean[\"Quarter\"], categories=quarter_order, ordered=True)\n",
        "        df_clean = df_clean[[\"Year\", \"Quarter\", \"Unit\", \"Total_Catch\"]]\n",
        "        df_clean[\"Year\"] = df_clean[\"Year\"].astype(int)\n",
        "\n",
        "        # Validate\n",
        "        if df_clean.isnull().any().any():\n",
        "            raise ValueError(\"New Total Catch data contains NaN values: \" + str(df_clean.head()))\n",
        "\n",
        "        # Insert new data into table\n",
        "        df_clean.to_sql('total_catch', conn, if_exists='append', index=False)\n",
        "        conn.commit()\n",
        "        print(\"Updated total_catch table with new data\")\n",
        "        display(df_clean.head())\n",
        "    else:\n",
        "        print(f\"Error fetching Total Catch data: {response.status_code} - {response.text}\")"
      ],
      "metadata": {
        "id": "EldUzBv9VlIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Update Fish Exports Data\n",
        "print(\"Updating Fish Exports Data...\")\n",
        "last_year, last_quarter = get_latest_period(\"fish_exports\", conn)\n",
        "if last_year is None:\n",
        "    print(\"No data found in fish_exports table. Run setup_dataset.ipynb first.\")\n",
        "else:\n",
        "    years_to_fetch, quarters_to_fetch = quarters_to_fetch(last_year, last_quarter)\n",
        "    print(f\"Last period in fish_exports: {last_year} {last_quarter}\")\n",
        "    print(f\"Fetching data for years: {years_to_fetch}, quarters: {quarters_to_fetch}\")\n",
        "\n",
        "    # Convert quarters to API format\n",
        "    api_quarters = [quarter_mapping[q] for q in quarters_to_fetch]\n",
        "\n",
        "    # Fetch new data\n",
        "    url = \"https://bank.stat.gl:443/api/v1/en/Greenland/IE/IE10/IEX2PROD.px\"\n",
        "    query = {\n",
        "        \"query\": [\n",
        "            {\"code\": \"branch\", \"selection\": {\"filter\": \"item\", \"values\": [\"46\"]}},\n",
        "            {\"code\": \"quarter\", \"selection\": {\"filter\": \"item\", \"values\": api_quarters}},\n",
        "            {\"code\": \"time\", \"selection\": {\"filter\": \"item\", \"values\": [str(y) for y in years_to_fetch]}}\n",
        "        ],\n",
        "        \"response\": {\"format\": \"json-stat2\"}\n",
        "    }\n",
        "    try:\n",
        "        response = requests.post(url, json=query)\n",
        "        response.raise_for_status()\n",
        "        dataset = pyjstat.Dataset.read(response.text)\n",
        "        df_fish_exports = dataset.write('dataframe')\n",
        "        print(\"New Fish Exports data retrieved!\")\n",
        "\n",
        "        # Clean DataFrame\n",
        "        df_fish_clean = df_fish_exports.copy()\n",
        "        column_mapping = {\n",
        "            \"time\": \"Year\",\n",
        "            \"quarter\": \"Quarter\",\n",
        "            \"value\": \"Fish_Export_Value_Million_Kr\"\n",
        "        }\n",
        "        if \"quarter\" not in df_fish_exports.columns and \"Quarter\" in df_fish_exports.columns:\n",
        "            column_mapping[\"Quarter\"] = \"Quarter\"\n",
        "            del column_mapping[\"quarter\"]\n",
        "        df_fish_clean.rename(columns=column_mapping, inplace=True)\n",
        "\n",
        "        if \"Quarter\" not in df_fish_clean.columns:\n",
        "            raise ValueError(\"Quarter column missing after renaming.\")\n",
        "        if df_fish_clean[\"Quarter\"].isnull().any():\n",
        "            raise ValueError(\"Quarter column contains NaN values: \" + str(df_fish_clean[\"Quarter\"].head()))\n",
        "\n",
        "        df_fish_clean[\"Quarter\"] = df_fish_clean[\"Quarter\"].str.replace(r\"[Qq]uarter \", \"Q\", regex=True)\n",
        "        df_fish_clean[\"Quarter\"] = pd.Categorical(df_fish_clean[\"Quarter\"], categories=quarter_order, ordered=True)\n",
        "        df_fish_clean = df_fish_clean.sort_values(by=[\"Year\", \"Quarter\"]).reset_index(drop=True)\n",
        "\n",
        "        # Convert export value to million Kr and round\n",
        "        df_fish_clean[\"Fish_Export_Value_Million_Kr\"] = df_fish_clean[\"Fish_Export_Value_Million_Kr\"] / 1e6\n",
        "        df_fish_clean[\"Fish_Export_Value_Million_Kr\"] = df_fish_clean[\"Fish_Export_Value_Million_Kr\"].round(0).astype(int)\n",
        "        df_fish_clean = df_fish_clean[[\"Year\", \"Quarter\", \"Fish_Export_Value_Million_Kr\"]]\n",
        "        df_fish_clean[\"Year\"] = df_fish_clean[\"Year\"].astype(int)\n",
        "\n",
        "        if df_fish_clean.isnull().any().any():\n",
        "            raise ValueError(\"New Fish Exports data contains NaN values.\")\n",
        "\n",
        "        # Insert new data into table\n",
        "        df_fish_clean.to_sql('fish_exports', conn, if_exists='append', index=False)\n",
        "        conn.commit()\n",
        "        print(\"Updated fish_exports table with new data\")\n",
        "        display(df_fish_clean.head())\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching Fish Exports data: {e}\")"
      ],
      "metadata": {
        "id": "Gxopz6AnVoaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Update Ice Melt and SST Data\n",
        "print(\"Updating Ice Melt and SST Data...\")\n",
        "last_year, last_quarter = get_latest_period(\"ice_melt_sst\", conn)\n",
        "if last_year is None:\n",
        "    print(\"No data found in ice_melt_sst table. Run setup_dataset.ipynb first.\")\n",
        "else:\n",
        "    years_to_fetch, quarters_to_fetch = quarters_to_fetch(last_year, last_quarter)\n",
        "    print(f\"Last period in ice_melt_sst: {last_year} {last_quarter}\")\n",
        "    print(f\"Fetching data for years: {years_to_fetch}, quarters: {quarters_to_fetch}\")\n",
        "\n",
        "    try:\n",
        "        start_year = last_year if quarters_to_fetch != [\"Q1\"] else last_year + 1\n",
        "        end_year = start_year + 1\n",
        "        start_date = f\"{start_year}-01-01\"\n",
        "        end_date = f\"{end_year}-01-01\"\n",
        "        url_template = \"https://psl.noaa.gov/thredds/dodsC/Datasets/ncep.reanalysis/Monthly/gaussian_grid/air.sfc.mon.mean.nc\"\n",
        "        ds = xr.open_dataset(url_template)\n",
        "        ds = ds.sel(time=slice(start_date, end_date))\n",
        "        west_lon_range = slice(300, 310)\n",
        "        east_lon_range = slice(350, 360)\n",
        "        greenland_lat_range = slice(85, 60)\n",
        "        sst_west = ds['air'].sel(lon=west_lon_range, lat=greenland_lat_range).mean(dim=['lat', 'lon'])\n",
        "        sst_east = ds['air'].sel(lon=east_lon_range, lat=greenland_lat_range).mean(dim=['lat', 'lon'])\n",
        "        sst_west_df = sst_west.to_dataframe().reset_index()\n",
        "        sst_east_df = sst_east.to_dataframe().reset_index()\n",
        "        sst_west_df['region'] = 'West'\n",
        "        sst_east_df['region'] = 'East'\n",
        "        sst_df = pd.concat([sst_west_df, sst_east_df], ignore_index=True)\n",
        "        sst_df.rename(columns={'time': 'Date', 'air': 'SST'}, inplace=True)\n",
        "\n",
        "        # Ice Melt Rate (simplified placeholder)\n",
        "        ice_melt_west = sst_west * 0.1\n",
        "        ice_melt_east = sst_east * 0.1\n",
        "        ice_melt_west_df = ice_melt_west.to_dataframe().reset_index()\n",
        "        ice_melt_east_df = ice_melt_east.to_dataframe().reset_index()\n",
        "        ice_melt_west_df['region'] = 'West'\n",
        "        ice_melt_east_df['region'] = 'East'\n",
        "        ice_melt_west_df.rename(columns={'air': 'Ice_Melt_Rate'}, inplace=True)\n",
        "        ice_melt_east_df.rename(columns={'air': 'Ice_Melt_Rate'}, inplace=True)\n",
        "\n",
        "        # Combine SST and Ice Melt\n",
        "        ice_melt_df = pd.concat([ice_melt_west_df, ice_melt_east_df], ignore_index=True)\n",
        "        ice_melt_df = ice_melt_df[['time', 'region', 'Ice_Melt_Rate']]\n",
        "        ice_melt_df.rename(columns={'time': 'Date'}, inplace=True)\n",
        "        df_melt_sst = pd.merge(sst_df, ice_melt_df, on=['Date', 'region'], how='inner')\n",
        "        df_melt_sst['Year'] = df_melt_sst['Date'].dt.year\n",
        "        df_melt_sst['Month'] = df_melt_sst['Date'].dt.month\n",
        "        df_melt_sst['Quarter'] = df_melt_sst['Month'].apply(lambda m: f\"Q{(m-1)//3 + 1}\")\n",
        "        df_melt_sst_clean = df_melt_sst.groupby(['Year', 'Quarter', 'region']).mean(numeric_only=True).reset_index()\n",
        "        df_melt_sst_clean = df_melt_sst_clean.pivot(index=['Year', 'Quarter'], columns='region', value=['SST', 'Ice_Melt_Rate']).reset_index()\n",
        "        df_melt_sst_clean.columns = ['Year', 'Quarter', 'Ice_Melt_Rate_East', 'Ice_Melt_Rate_West', 'SST_East', 'SST_West']\n",
        "        df_melt_sst_clean = df_melt_sst_clean[['Year', 'Quarter', 'Ice_Melt_Rate_East', 'Ice_Melt_Rate_West', 'SST_East', 'SST_West']]\n",
        "        quarter_order = [\"Q1\", \"Q2\", \"Q3\", \"Q4\"]\n",
        "        df_melt_sst_clean[\"Quarter\"] = pd.Categorical(df_melt_sst_clean[\"Quarter\"], categories=quarter_order, ordered=True)\n",
        "        df_melt_sst_clean = df_melt_sst_clean.sort_values(by=[\"Year\", \"Quarter\"]).reset_index(drop=True)\n",
        "\n",
        "        # Filter for the quarters we need\n",
        "        df_melt_sst_clean = df_melt_sst_clean[\n",
        "            (df_melt_sst_clean['Year'].isin(years_to_fetch)) &\n",
        "            (df_melt_sst_clean['Quarter'].isin(quarters_to_fetch))\n",
        "        ]\n",
        "\n",
        "        if df_melt_sst_clean.empty:\n",
        "            print(\"No new Ice Melt/SST data available for the specified periods.\")\n",
        "        else:\n",
        "            # Insert new data into table\n",
        "            df_melt_sst_clean.to_sql('ice_melt_sst', conn, if_exists='append', index=False)\n",
        "            conn.commit()\n",
        "            print(\"Updated ice_melt_sst table with new data\")\n",
        "            display(df_melt_sst_clean.head())\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching Ice Melt/SST data: {e}\")"
      ],
      "metadata": {
        "id": "bp6KAn4AVq0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Update Foreign Catch Data\n",
        "print(\"Updating Foreign Catch Data...\")\n",
        "last_year, last_quarter = get_latest_period(\"foreign_catch\", conn)\n",
        "if last_year is None:\n",
        "    print(\"No data found in foreign_catch table. Run setup_dataset.ipynb first.\")\n",
        "else:\n",
        "    years_to_fetch, quarters_to_fetch = quarters_to_fetch(last_year, last_quarter)\n",
        "    print(f\"Last period in foreign_catch: {last_year} {last_quarter}\")\n",
        "    print(f\"Fetching data for years: {years_to_fetch}, quarters: {quarters_to_fetch}\")\n",
        "\n",
        "    # Convert quarters to API format\n",
        "    api_quarters = [quarter_mapping[q] for q in quarters_to_fetch]\n",
        "\n",
        "    # Fetch new data\n",
        "    url = \"https://bank.stat.gl:443/api/v1/en/Greenland/FI/FI10/FIX008.px\"\n",
        "    query = {\n",
        "        \"query\": [\n",
        "            {\"code\": \"nation\", \"selection\": {\"filter\": \"item\", \"values\": [\"FOK\"]}},\n",
        "            {\"code\": \"unit\", \"selection\": {\"filter\": \"item\", \"values\": [\"Ton\"]}},\n",
        "            {\"code\": \"time\", \"selection\": {\"filter\": \"item\", \"values\": [str(y) for y in years_to_fetch]}},\n",
        "            {\"code\": \"quarter\", \"selection\": {\"filter\": \"item\", \"values\": api_quarters}}\n",
        "        ],\n",
        "        \"response\": {\"format\": \"json-stat2\"}\n",
        "    }\n",
        "    response = requests.post(url, json=query)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        dataset = pyjstat.Dataset.read(response.text)\n",
        "        df = dataset.write('dataframe')\n",
        "        print(\"New Foreign Catch data retrieved!\")\n",
        "\n",
        "        # Clean DataFrame\n",
        "        df_foreign_clean = df.copy()\n",
        "        df_foreign_clean.drop(columns=['nation'], inplace=True)\n",
        "        df_foreign_clean.rename(columns={\n",
        "            \"time\": \"Year\",\n",
        "            \"quarter\": \"Quarter\",\n",
        "            \"unit\": \"Unit\",\n",
        "            \"value\": \"Foreign_Catch\"\n",
        "        }, inplace=True)\n",
        "        df_foreign_clean[\"Quarter\"] = df_foreign_clean[\"Quarter\"].str.replace(\"Quarter \", \"Q\")\n",
        "        df_foreign_clean[\"Quarter\"] = pd.Categorical(df_foreign_clean[\"Quarter\"], categories=quarter_order, ordered=True)\n",
        "        df_foreign_clean = df_foreign_clean[[\"Year\", \"Quarter\", \"Unit\", \"Foreign_Catch\"]]\n",
        "        df_foreign_clean[\"Year\"] = df_foreign_clean[\"Year\"].astype(int)\n",
        "\n",
        "        if df_foreign_clean.isnull().any().any():\n",
        "            raise ValueError(\"New Foreign Catch data contains NaN values: \" + str(df_foreign_clean.head()))\n",
        "\n",
        "        # Insert new data into table\n",
        "        df_foreign_clean.to_sql('foreign_catch', conn, if_exists='append', index=False)\n",
        "        conn.commit()\n",
        "        print(\"Updated foreign_catch table with new data\")\n",
        "        display(df_foreign_clean.head())\n",
        "    else:\n",
        "        print(f\"Error fetching Foreign Catch data: {response.status_code} - {response.text}\")"
      ],
      "metadata": {
        "id": "2cqv3IBcVrKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Close the database connection\n",
        "conn.close()\n",
        "print(\"Database connection closed.\")"
      ],
      "metadata": {
        "id": "vu-0riJCVuEJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}