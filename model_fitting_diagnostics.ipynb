{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ccspen21/greenland-fishery-nowcast-2025/blob/main/model_fitting_diagnostics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas sqlite3 scikit-learn matplotlib\n",
        "import os\n",
        "import pandas as pd\n",
        "import sqlite3\n",
        "from sklearn.linear_model import Lasso, LassoCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from IPython.display import display\n",
        "\n",
        "# Ensure compatibility with Colab and GitHub\n",
        "!apt-get update && apt-get install -y iputils-ping\n",
        "\n",
        "# Define a configurable database path\n",
        "DB_PATH = os.getenv(\"DB_PATH\", \"greenland_fishery.db\")"
      ],
      "metadata": {
        "id": "1gmL0uSzy4QW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to the database\n",
        "try:\n",
        "    conn = sqlite3.connect(DB_PATH)\n",
        "    cursor = conn.cursor()\n",
        "    print(f\"Connected to SQLite database at {DB_PATH}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error connecting to database: {e}\")\n",
        "    raise\n",
        "\n",
        "# Helper function to validate DataFrame against schema\n",
        "def validate_dataframe(df, expected_columns, dtypes):\n",
        "    if not all(col in df.columns for col in expected_columns):\n",
        "        raise ValueError(f\"DataFrame missing expected columns: {expected_columns}\")\n",
        "    for col, dtype in dtypes.items():\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col].astype(dtype)\n",
        "    if df.isnull().any().any():\n",
        "        raise ValueError(f\"DataFrame contains NaN values: {df.head()}\")\n",
        "    if df.empty:\n",
        "        raise ValueError(\"DataFrame is empty. Ensure setup_dataset.ipynb has populated the database correctly.\")\n",
        "\n",
        "# Load data from tables with validation\n",
        "tables = {\n",
        "    \"total_catch\": ([\"Year\", \"Quarter\", \"Unit\", \"Total_Catch\"], {\"Year\": int, \"Quarter\": str, \"Unit\": str, \"Total_Catch\": int}),\n",
        "    \"fish_exports\": ([\"Year\", \"Quarter\", \"Fish_Export_Value_Million_Kr\"], {\"Year\": int, \"Quarter\": str, \"Fish_Export_Value_Million_Kr\": int}),\n",
        "    \"sst_west\": ([\"Year\", \"Quarter\", \"Sea_Surface_Temp_C_West\", \"Melt_Active_West\", \"Melt_Index_West\"], {\"Year\": int, \"Quarter\": str, \"Sea_Surface_Temp_C_West\": float, \"Melt_Active_West\": int, \"Melt_Index_West\": float}),\n",
        "    \"sst_east\": ([\"Year\", \"Quarter\", \"Sea_Surface_Temp_C_East\", \"Melt_Active_East\", \"Melt_Index_East\"], {\"Year\": int, \"Quarter\": str, \"Sea_Surface_Temp_C_East\": float, \"Melt_Active_East\": int, \"Melt_Index_East\": float}),\n",
        "    \"sst_south\": ([\"Year\", \"Quarter\", \"Sea_Surface_Temp_C_South\", \"Melt_Active_South\", \"Melt_Index_South\"], {\"Year\": int, \"Quarter\": str, \"Sea_Surface_Temp_C_South\": float, \"Melt_Active_South\": int, \"Melt_Index_South\": float}),\n",
        "    \"foreign_catch\": ([\"Year\", \"Quarter\", \"Unit\", \"Foreign_Catch\"], {\"Year\": int, \"Quarter\": str, \"Unit\": str, \"Foreign_Catch\": int}),\n",
        "}\n",
        "\n",
        "dataframes = {}\n",
        "for table_name, (expected_columns, dtypes) in tables.items():\n",
        "    try:\n",
        "        df = pd.read_sql_query(f\"SELECT * FROM {table_name}\", conn)\n",
        "        validate_dataframe(df, expected_columns, dtypes)\n",
        "        dataframes[table_name] = df\n",
        "        print(f\"Loaded {table_name}:\")\n",
        "        display(df.head())\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {table_name}: {e}\")\n",
        "        raise  # Stop execution to alert the user to fix the issue\n",
        "\n",
        "# Assign to variables expected by later cells\n",
        "df_clean = dataframes[\"total_catch\"]\n",
        "df_fish_clean = dataframes[\"fish_exports\"]\n",
        "df_sst_west_clean = dataframes[\"sst_west\"]\n",
        "df_sst_east_clean = dataframes[\"sst_east\"]\n",
        "df_sst_south_clean = dataframes[\"sst_south\"]\n",
        "df_foreign_clean = dataframes[\"foreign_catch\"]"
      ],
      "metadata": {
        "id": "h_wga5rkyzMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3-Way Interaction Term"
      ],
      "metadata": {
        "id": "I8RzSDhNWEE3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create three-way interaction terms in each SST regional DataFrame\n",
        "df_sst_west_clean[\"Melt_SST_Interaction_West\"] = (\n",
        "    df_sst_west_clean[\"Melt_Active_West\"] *\n",
        "    df_sst_west_clean[\"Melt_Index_West\"] *\n",
        "    df_sst_west_clean[\"Sea_Surface_Temp_C_West\"]\n",
        ")\n",
        "\n",
        "df_sst_east_clean[\"Melt_SST_Interaction_East\"] = (\n",
        "    df_sst_east_clean[\"Melt_Active_East\"] *\n",
        "    df_sst_east_clean[\"Melt_Index_East\"] *\n",
        "    df_sst_east_clean[\"Sea_Surface_Temp_C_East\"]\n",
        ")\n",
        "\n",
        "df_sst_south_clean[\"Melt_SST_Interaction_South\"] = (\n",
        "    df_sst_south_clean[\"Melt_Active_South\"] *\n",
        "    df_sst_south_clean[\"Melt_Index_South\"] *\n",
        "    df_sst_south_clean[\"Sea_Surface_Temp_C_South\"]\n",
        ")"
      ],
      "metadata": {
        "id": "8thEvL9lWD0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Merged Dataset"
      ],
      "metadata": {
        "id": "23fbvpzLWvjq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGV5YQrx6c5o"
      },
      "outputs": [],
      "source": [
        "# Ensure all 'Year' and 'Quarter' columns are of consistent type across DataFrames\n",
        "# Note: Quarter is already in Q1, Q2, etc. format from setup_dataset.ipynb, but we'll ensure types are consistent\n",
        "df_clean[\"Year\"] = df_clean[\"Year\"].astype(int)\n",
        "df_clean[\"Quarter\"] = df_clean[\"Quarter\"].astype(str)\n",
        "df_fish_clean[\"Year\"] = df_fish_clean[\"Year\"].astype(int)\n",
        "df_fish_clean[\"Quarter\"] = df_fish_clean[\"Quarter\"].astype(str)\n",
        "df_foreign_clean[\"Year\"] = df_foreign_clean[\"Year\"].astype(int)\n",
        "df_foreign_clean[\"Quarter\"] = df_foreign_clean[\"Quarter\"].astype(str)\n",
        "df_sst_west_clean[\"Year\"] = df_sst_west_clean[\"Year\"].astype(int)\n",
        "df_sst_west_clean[\"Quarter\"] = df_sst_west_clean[\"Quarter\"].astype(str)\n",
        "df_sst_east_clean[\"Year\"] = df_sst_east_clean[\"Year\"].astype(int)\n",
        "df_sst_east_clean[\"Quarter\"] = df_sst_east_clean[\"Quarter\"].astype(str)\n",
        "df_sst_south_clean[\"Year\"] = df_sst_south_clean[\"Year\"].astype(int)\n",
        "df_sst_south_clean[\"Quarter\"] = df_sst_south_clean[\"Quarter\"].astype(str)\n",
        "\n",
        "# Start fresh from df_clean\n",
        "df_merged_with_interactions = df_clean.copy()\n",
        "\n",
        "# Merge standard right-hand-side variables\n",
        "df_merged_with_interactions = df_merged_with_interactions.merge(df_fish_clean, on=[\"Year\", \"Quarter\"], how=\"inner\")\n",
        "\n",
        "# Merge SST interaction terms\n",
        "df_merged_with_interactions = df_merged_with_interactions.merge(\n",
        "    df_sst_west_clean[[\"Year\", \"Quarter\", \"Melt_SST_Interaction_West\"]],\n",
        "    on=[\"Year\", \"Quarter\"], how=\"inner\"\n",
        ").merge(\n",
        "    df_sst_east_clean[[\"Year\", \"Quarter\", \"Melt_SST_Interaction_East\"]],\n",
        "    on=[\"Year\", \"Quarter\"], how=\"inner\"\n",
        ").merge(\n",
        "    df_sst_south_clean[[\"Year\", \"Quarter\", \"Melt_SST_Interaction_South\"]],\n",
        "    on=[\"Year\", \"Quarter\"], how=\"inner\"\n",
        ")\n",
        "\n",
        "# Merge foreign catch\n",
        "df_merged_with_interactions = df_merged_with_interactions.merge(\n",
        "    df_foreign_clean.drop(columns=[\"Unit\"]),\n",
        "    on=[\"Year\", \"Quarter\"], how=\"left\"\n",
        ")\n",
        "\n",
        "# Drop unnecessary columns\n",
        "df_merged_with_interactions = df_merged_with_interactions.drop(\n",
        "    columns=[col for col in df_merged_with_interactions.columns if \"Unit\" in col], errors=\"ignore\"\n",
        ")\n",
        "\n",
        "# Log dropped rows after merging\n",
        "original_len = len(df_merged_with_interactions)\n",
        "df_merged_with_interactions = df_merged_with_interactions.dropna()\n",
        "dropped_rows = original_len - len(df_merged_with_interactions)\n",
        "if dropped_rows > 0:\n",
        "    print(f\"Dropped {dropped_rows} rows due to missing values after merging\")\n",
        "\n",
        "# Order\n",
        "df_merged_with_interactions[\"Quarter\"] = pd.Categorical(\n",
        "    df_merged_with_interactions[\"Quarter\"], categories=[\"Q1\", \"Q2\", \"Q3\", \"Q4\"], ordered=True\n",
        ")\n",
        "df_merged_with_interactions = df_merged_with_interactions.sort_values(by=[\"Year\", \"Quarter\"]).reset_index(drop=True)\n",
        "\n",
        "print(\"✅ Final merged dataset shape:\", df_merged_with_interactions.shape)\n",
        "display(df_merged_with_interactions.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LASSO Regression"
      ],
      "metadata": {
        "id": "e227U7xjXWxU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wfX38cJWpzI"
      },
      "outputs": [],
      "source": [
        "# Step 1: Identify predictors to lag (exclude Total_Catch and lagged versions)\n",
        "predictor_cols = [\n",
        "    col for col in df_merged_with_interactions.columns\n",
        "    if col not in [\"Year\", \"Quarter\", \"Total_Catch\"]\n",
        "    and not col.endswith(\"_lag1\")\n",
        "    and not col.endswith(\"_lag2\")\n",
        "    and not col.endswith(\"_lag3\")\n",
        "    and not col.endswith(\"_lag4\")\n",
        "]\n",
        "\n",
        "print(\"🔍 Predictors to lag:\", predictor_cols)\n",
        "\n",
        "# Step 2: Add lags 1–4 for each selected predictor\n",
        "for col in predictor_cols:\n",
        "    for lag in [1, 2, 3, 4]:\n",
        "        df_merged_with_interactions[f\"{col}_lag{lag}\"] = df_merged_with_interactions[col].shift(lag)\n",
        "\n",
        "# Step 3: Add lags 1–4 for Total_Catch\n",
        "for lag in [1, 2, 3, 4]:\n",
        "    df_merged_with_interactions[f\"Total_Catch_lag{lag}\"] = df_merged_with_interactions[\"Total_Catch\"].shift(lag)\n",
        "\n",
        "# Step 4: Drop original (non-lagged) predictors\n",
        "df_model_with_interactions = df_merged_with_interactions.drop(columns=predictor_cols)\n",
        "\n",
        "# Step 5: Drop rows with NA from lagging\n",
        "df_model_with_interactions = df_model_with_interactions.dropna().reset_index(drop=True)\n",
        "\n",
        "# Step 6: Define modeling dataset\n",
        "y = df_model_with_interactions[\"Total_Catch\"]\n",
        "X = df_model_with_interactions.drop(columns=[\"Year\", \"Quarter\", \"Total_Catch\"])\n",
        "\n",
        "# ✅ Final shape check\n",
        "print(\"✅ Clean setup with lags 1–4 — X shape:\", X.shape, \"y shape:\", y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Selected Variables"
      ],
      "metadata": {
        "id": "FANT4TqFYDE0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yia9EeMZXB4t"
      },
      "outputs": [],
      "source": [
        "# Step 1: Create LASSO pipeline with standardization and cross-validated alpha\n",
        "lasso_pipeline = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    LassoCV(cv=5, random_state=42, max_iter=50000)\n",
        ")\n",
        "\n",
        "# Step 2: Fit the model\n",
        "lasso_pipeline.fit(X, y)\n",
        "\n",
        "# Step 3: Extract coefficients into a clean DataFrame\n",
        "lasso_model = lasso_pipeline.named_steps[\"lassocv\"]\n",
        "coef = pd.Series(lasso_model.coef_, index=X.columns)\n",
        "\n",
        "# Step 4: Display selected variables (non-zero)\n",
        "selected = coef[coef != 0]\n",
        "print(\"✅ Selected variables with 4 lags:\\n\", selected)\n",
        "\n",
        "# Step 5: Plot all coefficients\n",
        "plt.figure(figsize=(12, 6))\n",
        "coef.plot(kind='barh')\n",
        "plt.title(\"LASSO Coefficients (with lags 1–4)\")\n",
        "plt.axvline(0, color='gray', linestyle='--')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluation**"
      ],
      "metadata": {
        "id": "QUcuZzQ3YjMY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LASSO Coefficients"
      ],
      "metadata": {
        "id": "qw_vk3qGaAj8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCuhLhR5uebh"
      },
      "outputs": [],
      "source": [
        "# Extract fitted model from pipeline\n",
        "lasso_model = lasso_pipeline.named_steps['lassocv']\n",
        "\n",
        "# Define variable names used (updated to match schema)\n",
        "feature_names = [\n",
        "    \"Total_Catch_lag4\",\n",
        "    \"Foreign_Catch_lag4\",\n",
        "    \"Melt_SST_Interaction_West_lag4\",\n",
        "    \"Melt_SST_Interaction_East_lag1\",\n",
        "    \"Fish_Export_Value_Million_Kr_lag2\"\n",
        "]\n",
        "\n",
        "# Create a DataFrame of coefficients\n",
        "coef_df = pd.DataFrame({\n",
        "    \"LASSO\": lasso_model.coef_,\n",
        "}, index=feature_names)\n",
        "\n",
        "# Round for cleaner display\n",
        "coef_df = coef_df.round(0).astype(int)\n",
        "\n",
        "# Display\n",
        "display(coef_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Out-of-Sample Performance - Backtests"
      ],
      "metadata": {
        "id": "rVzUzo4kYoGj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q4 2024"
      ],
      "metadata": {
        "id": "qogOf0VGZIph"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKj7blI1Y4cW"
      },
      "outputs": [],
      "source": [
        "# Step 1: Filter training data (up to Q3 2024 only)\n",
        "train_q4 = df_model_with_interactions[\n",
        "    (df_model_with_interactions[\"Year\"] < 2024) |\n",
        "    ((df_model_with_interactions[\"Year\"] == 2024) & (df_model_with_interactions[\"Quarter\"] < \"Q4\"))\n",
        "]\n",
        "\n",
        "X_train_q4 = train_q4[[\n",
        "    \"Total_Catch_lag4\",\n",
        "    \"Melt_SST_Interaction_West_lag4\",\n",
        "    \"Foreign_Catch_lag4\",\n",
        "    \"Melt_SST_Interaction_East_lag1\",\n",
        "    \"Fish_Export_Value_Million_Kr_lag2\"\n",
        "]]\n",
        "\n",
        "y_train_q4 = train_q4[\"Total_Catch\"]\n",
        "print(\"✅ Training set size for Q4 2024 (Top 5 Vars):\", X_train_q4.shape)\n",
        "\n",
        "# Step 2: Create nowcast input row for Q4 2024\n",
        "try:\n",
        "    latest_row_q3 = df_model_with_interactions[\n",
        "        (df_model_with_interactions[\"Year\"] == 2024) & (df_model_with_interactions[\"Quarter\"] == \"Q3\")\n",
        "    ].iloc[0]\n",
        "except IndexError:\n",
        "    print(\"Error: Q3 2024 data not found. Ensure periodic_update.ipynb has been run to fetch the latest data.\")\n",
        "    raise\n",
        "\n",
        "X_nowcast_q4 = pd.DataFrame([{\n",
        "    \"Total_Catch_lag4\": df_model_with_interactions.iloc[-5][\"Total_Catch_lag4\"],                          # Q4 2023\n",
        "    \"Melt_SST_Interaction_West_lag4\": df_model_with_interactions.iloc[-5][\"Melt_SST_Interaction_West_lag4\"],\n",
        "    \"Foreign_Catch_lag4\": df_model_with_interactions.iloc[-5][\"Foreign_Catch_lag4\"],\n",
        "    \"Melt_SST_Interaction_East_lag1\": df_model_with_interactions.iloc[-2][\"Melt_SST_Interaction_East_lag1\"],\n",
        "    \"Fish_Export_Value_Million_Kr_lag2\": df_model_with_interactions.iloc[-5][\"Fish_Export_Value_Million_Kr_lag2\"]\n",
        "}])\n",
        "\n",
        "print(\"✅ Nowcast input row for Q4 2024 (5 vars):\")\n",
        "display(X_nowcast_q4)\n",
        "\n",
        "# Step 3: Fit LASSO model\n",
        "lasso_pipeline_q4 = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    Lasso(alpha=1.0, max_iter=10000)\n",
        ")\n",
        "\n",
        "lasso_pipeline_q4.fit(X_train_q4, y_train_q4)\n",
        "\n",
        "# Step 4: Predict Q4 2024\n",
        "y_pred_q4_2024_lasso = lasso_pipeline_q4.predict(X_nowcast_q4)[0]\n",
        "print(f\"📈 🧪 Nowcast for Q4 2024 (LASSO, Fish Export included): {round(y_pred_q4_2024_lasso):,.0f} tons\")\n",
        "\n",
        "# Step 5: Compare with actual\n",
        "try:\n",
        "    actual_q4 = df_model_with_interactions[\n",
        "        (df_model_with_interactions[\"Year\"] == 2024) & (df_model_with_interactions[\"Quarter\"] == \"Q4\")\n",
        "    ][\"Total_Catch\"].values[0]\n",
        "except IndexError:\n",
        "    print(\"Error: Q4 2024 actual data not found. Cannot compute forecast error.\")\n",
        "    raise\n",
        "\n",
        "error_q4 = y_pred_q4_2024_lasso - actual_q4\n",
        "print(f\"🎯 Actual Q4 2024: {round(actual_q4):,.0f} tons\")\n",
        "print(f\"🔍 Forecast Error: {round(error_q4):,.0f} tons ({round(100 * error_q4 / actual_q4, 1)}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q3 2024"
      ],
      "metadata": {
        "id": "byEwx1h9ZfXF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xmgs1YWghyn"
      },
      "outputs": [],
      "source": [
        "# Step 1: Filter training data up to Q2 2024 (exclude Q3)\n",
        "train_q3 = df_model_with_interactions[\n",
        "    (df_model_with_interactions[\"Year\"] < 2024) |\n",
        "    ((df_model_with_interactions[\"Year\"] == 2024) & (df_model_with_interactions[\"Quarter\"] < \"Q3\"))\n",
        "]\n",
        "\n",
        "X_train_q3 = train_q3[[\n",
        "    \"Total_Catch_lag4\",\n",
        "    \"Melt_SST_Interaction_West_lag4\",\n",
        "    \"Foreign_Catch_lag4\",\n",
        "    \"Melt_SST_Interaction_East_lag1\",\n",
        "    \"Fish_Export_Value_Million_Kr_lag2\"\n",
        "]]\n",
        "y_train_q3 = train_q3[\"Total_Catch\"]\n",
        "print(\"✅ Training set size for Q3 2024 (5 vars):\", X_train_q3.shape)\n",
        "\n",
        "# Step 2: Create nowcast input row for Q3 2024\n",
        "try:\n",
        "    latest_row_q2 = df_model_with_interactions[\n",
        "        (df_model_with_interactions[\"Year\"] == 2024) & (df_model_with_interactions[\"Quarter\"] == \"Q2\")\n",
        "    ].iloc[0]\n",
        "except IndexError:\n",
        "    print(\"Error: Q2 2024 data not found. Ensure periodic_update.ipynb has been run to fetch the latest data.\")\n",
        "    raise\n",
        "\n",
        "X_nowcast_q3 = pd.DataFrame([{\n",
        "    \"Total_Catch_lag4\": df_model_with_interactions.iloc[-6][\"Total_Catch_lag4\"],                          # Q3 2023\n",
        "    \"Melt_SST_Interaction_West_lag4\": df_model_with_interactions.iloc[-6][\"Melt_SST_Interaction_West_lag4\"],\n",
        "    \"Foreign_Catch_lag4\": df_model_with_interactions.iloc[-6][\"Foreign_Catch_lag4\"],\n",
        "    \"Melt_SST_Interaction_East_lag1\": df_model_with_interactions.iloc[-3][\"Melt_SST_Interaction_East_lag1\"],\n",
        "    \"Fish_Export_Value_Million_Kr_lag2\": df_model_with_interactions.iloc[-6][\"Fish_Export_Value_Million_Kr_lag2\"]\n",
        "}])\n",
        "\n",
        "print(\"✅ Nowcast input row for Q3 2024 (5 vars):\")\n",
        "display(X_nowcast_q3)\n",
        "\n",
        "# Step 3: Fit LASSO model\n",
        "lasso_pipeline_q3 = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    Lasso(alpha=1.0, max_iter=10000)\n",
        ")\n",
        "\n",
        "lasso_pipeline_q3.fit(X_train_q3, y_train_q3)\n",
        "\n",
        "# Step 4: Predict Q3 2024\n",
        "y_pred_q3_2024_lasso = lasso_pipeline_q3.predict(X_nowcast_q3)[0]\n",
        "print(f\"📈 🧪 Nowcast for Q3 2024 (LASSO, Fish Export included): {round(y_pred_q3_2024_lasso):,.0f} tons\")\n",
        "\n",
        "# Step 5: Compare with actual\n",
        "try:\n",
        "    actual_q3 = df_model_with_interactions[\n",
        "        (df_model_with_interactions[\"Year\"] == 2024) & (df_model_with_interactions[\"Quarter\"] == \"Q3\")\n",
        "    ][\"Total_Catch\"].values[0]\n",
        "except IndexError:\n",
        "    print(\"Error: Q3 2024 actual data not found. Cannot compute forecast error.\")\n",
        "    raise\n",
        "\n",
        "error_q3 = y_pred_q3_2024_lasso - actual_q3\n",
        "print(f\"🎯 Actual Q3 2024: {round(actual_q3):,.0f} tons\")\n",
        "print(f\"🔍 Forecast Error: {round(error_q3):,.0f} tons ({round(100 * error_q3 / actual_q3, 1)}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q2 2024"
      ],
      "metadata": {
        "id": "5kGs4wj1ZlIk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JwYCKmHvvXsb"
      },
      "outputs": [],
      "source": [
        "q2_vars = [\n",
        "    \"Total_Catch_lag4\",\n",
        "    \"Foreign_Catch_lag4\",\n",
        "    \"Melt_SST_Interaction_West_lag4\",\n",
        "    \"Melt_SST_Interaction_East_lag1\",\n",
        "    \"Fish_Export_Value_Million_Kr_lag2\"\n",
        "]\n",
        "\n",
        "# Step 1: Training data up to Q1 2024 (exclude Q2)\n",
        "train_q2 = df_model_with_interactions[\n",
        "    (df_model_with_interactions[\"Year\"] < 2024) |\n",
        "    ((df_model_with_interactions[\"Year\"] == 2024) & (df_model_with_interactions[\"Quarter\"] < \"Q2\"))\n",
        "]\n",
        "\n",
        "X_train_q2 = train_q2[[\n",
        "    \"Total_Catch_lag4\",\n",
        "    \"Foreign_Catch_lag4\",\n",
        "    \"Melt_SST_Interaction_West_lag4\",\n",
        "    \"Melt_SST_Interaction_East_lag1\",\n",
        "    \"Fish_Export_Value_Million_Kr_lag2\"\n",
        "]]\n",
        "y_train_q2 = train_q2[\"Total_Catch\"]\n",
        "\n",
        "print(\"✅ Training set size for Q2 2024 (LASSO):\", X_train_q2.shape)\n",
        "\n",
        "# Step 2: Create nowcast input row for Q2 2024\n",
        "try:\n",
        "    latest_row_q1 = df_model_with_interactions[\n",
        "        (df_model_with_interactions[\"Year\"] == 2024) &\n",
        "        (df_model_with_interactions[\"Quarter\"] == \"Q1\")\n",
        "    ].iloc[0]\n",
        "except IndexError:\n",
        "    print(\"Error: Q1 2024 data not found. Ensure periodic_update.ipynb has been run to fetch the latest data.\")\n",
        "    raise\n",
        "\n",
        "X_nowcast_q2 = pd.DataFrame([{\n",
        "    \"Total_Catch_lag4\": df_model_with_interactions.iloc[-7][\"Total_Catch_lag4\"],  # Q2 2023\n",
        "    \"Foreign_Catch_lag4\": df_model_with_interactions.iloc[-7][\"Foreign_Catch_lag4\"],\n",
        "    \"Melt_SST_Interaction_West_lag4\": df_model_with_interactions.iloc[-7][\"Melt_SST_Interaction_West_lag4\"],\n",
        "    \"Melt_SST_Interaction_East_lag1\": df_model_with_interactions.iloc[-4][\"Melt_SST_Interaction_East_lag1\"],  # Q1 2024\n",
        "    \"Fish_Export_Value_Million_Kr_lag2\": df_model_with_interactions.iloc[-7][\"Fish_Export_Value_Million_Kr_lag2\"]\n",
        "}])\n",
        "\n",
        "print(\"✅ Nowcast input for Q2 2024 (LASSO):\")\n",
        "display(X_nowcast_q2)\n",
        "\n",
        "# Step 3: Fit LASSO pipeline\n",
        "lasso_pipeline_q2 = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    Lasso(alpha=1.0, max_iter=10000)\n",
        ")\n",
        "\n",
        "lasso_pipeline_q2.fit(X_train_q2, y_train_q2)\n",
        "y_pred_q2_2024_lasso = lasso_pipeline_q2.predict(X_nowcast_q2)[0]\n",
        "\n",
        "# Step 4: Compare with actual\n",
        "try:\n",
        "    actual_q2 = df_model_with_interactions[\n",
        "        (df_model_with_interactions[\"Year\"] == 2024) &\n",
        "        (df_model_with_interactions[\"Quarter\"] == \"Q2\")\n",
        "    ][\"Total_Catch\"].values[0]\n",
        "except IndexError:\n",
        "    print(\"Error: Q2 2024 actual data not found. Cannot compute forecast error.\")\n",
        "    raise\n",
        "\n",
        "error_q2_lasso = y_pred_q2_2024_lasso - actual_q2\n",
        "print(f\"📊 LASSO Nowcast for Q2 2024: {round(y_pred_q2_2024_lasso):,.0f} tons\")\n",
        "print(f\"🎯 Actual Q2 2024: {round(actual_q2):,.0f} tons\")\n",
        "print(f\"🔍 Forecast Error: {round(error_q2_lasso):,.0f} tons ({round(100 * error_q2_lasso / actual_q2, 1)}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q1 2024"
      ],
      "metadata": {
        "id": "mUAu_ze1Zwjv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_sEI0pv6wAnq"
      },
      "outputs": [],
      "source": [
        "# Step 1: Training data up to Q4 2023 (exclude Q1 2024)\n",
        "train_q1 = df_model_with_interactions[\n",
        "    (df_model_with_interactions[\"Year\"] < 2024)\n",
        "]\n",
        "\n",
        "X_train_q1 = train_q1[[\n",
        "    \"Total_Catch_lag4\",\n",
        "    \"Foreign_Catch_lag4\",\n",
        "    \"Melt_SST_Interaction_West_lag4\",\n",
        "    \"Melt_SST_Interaction_East_lag1\",\n",
        "    \"Fish_Export_Value_Million_Kr_lag2\"\n",
        "]]\n",
        "y_train_q1 = train_q1[\"Total_Catch\"]\n",
        "\n",
        "print(\"✅ Training set size for Q1 2024 (LASSO):\", X_train_q1.shape)\n",
        "\n",
        "# Step 2: Create nowcast input row for Q1 2024\n",
        "try:\n",
        "    latest_row_q4_2023 = df_model_with_interactions[\n",
        "        (df_model_with_interactions[\"Year\"] == 2023) &\n",
        "        (df_model_with_interactions[\"Quarter\"] == \"Q4\")\n",
        "    ].iloc[0]\n",
        "except IndexError:\n",
        "    print(\"Error: Q4 2023 data not found. Ensure setup_dataset.ipynb or periodic_update.ipynb has been run to fetch the latest data.\")\n",
        "    raise\n",
        "\n",
        "X_nowcast_q1 = pd.DataFrame([{\n",
        "    \"Total_Catch_lag4\": df_model_with_interactions.iloc[-8][\"Total_Catch_lag4\"],  # Q1 2023\n",
        "    \"Foreign_Catch_lag4\": df_model_with_interactions.iloc[-8][\"Foreign_Catch_lag4\"],\n",
        "    \"Melt_SST_Interaction_West_lag4\": df_model_with_interactions.iloc[-8][\"Melt_SST_Interaction_West_lag4\"],\n",
        "    \"Melt_SST_Interaction_East_lag1\": df_model_with_interactions.iloc[-5][\"Melt_SST_Interaction_East_lag1\"],  # Q4 2023\n",
        "    \"Fish_Export_Value_Million_Kr_lag2\": df_model_with_interactions.iloc[-8][\"Fish_Export_Value_Million_Kr_lag2\"]\n",
        "}])\n",
        "\n",
        "print(\"✅ Nowcast input for Q1 2024 (LASSO):\")\n",
        "display(X_nowcast_q1)\n",
        "\n",
        "# Step 3: Fit LASSO model\n",
        "lasso_pipeline_q1 = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    Lasso(alpha=1.0, max_iter=10000)\n",
        ")\n",
        "\n",
        "lasso_pipeline_q1.fit(X_train_q1, y_train_q1)\n",
        "y_pred_q1_2024_lasso = lasso_pipeline_q1.predict(X_nowcast_q1)[0]\n",
        "\n",
        "# Step 4: Compare with actual\n",
        "try:\n",
        "    actual_q1 = df_model_with_interactions[\n",
        "        (df_model_with_interactions[\"Year\"] == 2024) &\n",
        "        (df_model_with_interactions[\"Quarter\"] == \"Q1\")\n",
        "    ][\"Total_Catch\"].values[0]\n",
        "except IndexError:\n",
        "    print(\"Error: Q1 2024 actual data not found. Cannot compute forecast error.\")\n",
        "    raise\n",
        "\n",
        "error_q1_lasso = y_pred_q1_2024_lasso - actual_q1\n",
        "print(f\"📊 LASSO Nowcast for Q1 2024: {round(y_pred_q1_2024_lasso):,.0f} tons\")\n",
        "print(f\"🎯 Actual Q1 2024: {round(actual_q1):,.0f} tons\")\n",
        "print(f\"🔍 Forecast Error: {round(error_q1_lasso):,.0f} tons ({round(100 * error_q1_lasso / actual_q1, 1)}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MAE for Backtests"
      ],
      "metadata": {
        "id": "Xr13fUJsbH1_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4PVR4nxmJna"
      },
      "outputs": [],
      "source": [
        "# Q1 MAE\n",
        "mae_q1_lasso = abs(y_pred_q1_2024_lasso - actual_q1)\n",
        "\n",
        "# Q2 MAE\n",
        "mae_q2_lasso = abs(y_pred_q2_2024_lasso - actual_q2)\n",
        "\n",
        "# Q3 MAE\n",
        "mae_q3_lasso = abs(y_pred_q3_2024_lasso - actual_q3)\n",
        "\n",
        "# Q4 MAE\n",
        "mae_q4_lasso = abs(y_pred_q4_2024_lasso - actual_q4)\n",
        "\n",
        "# Average MAE across all quarters\n",
        "avg_mae_lasso = (mae_q1_lasso + mae_q2_lasso + mae_q3_lasso + mae_q4_lasso) / 4\n",
        "\n",
        "# Display the MAE comparison table\n",
        "print(\"📊 MAE Comparison Table (Q1–Q4 2024 Backtests)\")\n",
        "print(\"------------------------------------------------\")\n",
        "print(f\"Q1 2024 MAE - LASSO:        {mae_q1_lasso:,.0f}\")\n",
        "print(f\"Q2 2024 MAE - LASSO:        {mae_q2_lasso:,.0f}\")\n",
        "print(f\"Q3 2024 MAE - LASSO:        {mae_q3_lasso:,.0f}\")\n",
        "print(f\"Q4 2024 MAE - LASSO:        {mae_q4_lasso:,.0f}\")\n",
        "print(\"------------------------------------------------\")\n",
        "print(f\"Avg MAE     - LASSO:        {avg_mae_lasso:,.0f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# In-Sample Performance"
      ],
      "metadata": {
        "id": "XELBLL5cZhUZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# ✅ In-sample predictions (using Q1 training data)\n",
        "y_pred_lasso_train = lasso_pipeline_q1.predict(X_train_q1)\n",
        "\n",
        "# ✅ LASSO metrics\n",
        "print(\"🔍 LASSO In-Sample Performance:\")\n",
        "print(\"MAE:\", mean_absolute_error(y_train_q1, y_pred_lasso_train))"
      ],
      "metadata": {
        "id": "5oPaTqbuajJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given the nature of fish catch in Greenland, which is heavily influenced by policy shocks, quota trading, and environmental volatility, MAE is a more appropriate metric than RMSE or R². It offers a stable, interpretable measure of predictive accuracy that reflects the average deviation in real-world units (tons), without over-penalizing policy-driven anomalies."
      ],
      "metadata": {
        "id": "phgwEIKxayXX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Close the database connection\n",
        "try:\n",
        "    conn.close()\n",
        "    print(\"Database connection closed.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error closing database connection: {e}\")"
      ],
      "metadata": {
        "id": "R1ijIGsv0uNV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}